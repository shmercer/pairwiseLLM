<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Pairwise Writing Quality Comparisons with Large Language Models • pairwiseLLM</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Pairwise Writing Quality Comparisons with Large Language Models">
<meta name="description" content="What the package does (one paragraph).">
<meta property="og:description" content="What the package does (one paragraph).">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">pairwiseLLM</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="articles/prompt-template-positional-bias.html">Prompt Template Positional Bias Testing</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/shmercer/pairwiseLLM/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="pairwisellm-pairwise-comparisons-of-writing-quality-with-llms">pairwiseLLM: Pairwise comparisons of writing quality with LLMs<a class="anchor" aria-label="anchor" href="#pairwisellm-pairwise-comparisons-of-writing-quality-with-llms"></a>
</h1></div>
<!-- badges: start -->

<p><code>pairwiseLLM</code> is an R package that provides a unified framework for generating, submitting, and modeling <strong>pairwise comparisons of writing quality</strong> from large language models (LLMs).</p>
<p>It supports:</p>
<ul>
<li><p>Multiple providers: OpenAI, Anthropic, Google Gemini, and (planned) local models via <code>Ollama</code></p></li>
<li><p>Live and batch processing pipelines for all supported cloud providers.</p></li>
<li><p>A default prompt template, designed (and tested) to reduce positional bias.</p></li>
<li><p>Built-in tools for positional-bias diagnostics</p></li>
<li><p>Bradley-Terry (BT) modeling to convert pairwise comparison results into latent ability scores</p></li>
<li><p>Consistent output tibbles across all backends.</p></li>
</ul>
<div class="section level2">
<h2 id="supported-models">Supported Models<a class="anchor" aria-label="anchor" href="#supported-models"></a>
</h2>
<p>The following models are confirmed to work with pairwiseLLM for live and batch pairwise comparisons. The table notes whether each model supports thinking / reasoning traces (e.g., <code>include_thoughts = TRUE</code> via OpenAI <code>reasoning</code>, Anthropic <code>thinking</code>, Gemini <code>thinkingConfig</code>).</p>
<table class="table">
<thead><tr class="header">
<th>Provider</th>
<th>Model</th>
<th>Thinking Supported?</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>OpenAI</strong></td>
<td>gpt-5.1</td>
<td>✅ Yes</td>
</tr>
<tr class="even">
<td><strong>OpenAI</strong></td>
<td>gpt-4.1</td>
<td>❌ No</td>
</tr>
<tr class="odd">
<td><strong>OpenAI</strong></td>
<td>gpt-4.1-mini</td>
<td>❌ No</td>
</tr>
<tr class="even">
<td><strong>OpenAI</strong></td>
<td>gpt-4.1-nano</td>
<td>❌ No</td>
</tr>
<tr class="odd">
<td><strong>OpenAI</strong></td>
<td>gpt-4o</td>
<td>❌ No</td>
</tr>
<tr class="even">
<td><strong>Anthropic</strong></td>
<td>claude-sonnet-4-5</td>
<td>✅ Yes</td>
</tr>
<tr class="odd">
<td><strong>Anthropic</strong></td>
<td>claude-haiku-4-5</td>
<td>✅ Yes</td>
</tr>
<tr class="even">
<td><strong>Anthropic</strong></td>
<td>claude-opus-4-5</td>
<td>✅ Yes</td>
</tr>
<tr class="odd">
<td><strong>Anthropic</strong></td>
<td>claude-opus-4-1</td>
<td>✅ Yes</td>
</tr>
<tr class="even">
<td><strong>Anthropic</strong></td>
<td>claude-sonnet-4-0</td>
<td>✅ Yes</td>
</tr>
<tr class="odd">
<td><strong>Anthropic</strong></td>
<td>claude-opus-4-0</td>
<td>✅ Yes</td>
</tr>
<tr class="even">
<td><strong>Gemini</strong></td>
<td>gemini-3-pro-preview</td>
<td>✅ Yes</td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>From GitHub (development version):</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install.packages("pak")</span></span>
<span><span class="fu">pak</span><span class="fu">::</span><span class="fu"><a href="https://pak.r-lib.org/reference/pak.html" class="external-link">pak</a></span><span class="op">(</span><span class="st">"shmercer/pairwiseLLM"</span><span class="op">)</span></span></code></pre></div>
<p>You can then load the package in the usual way:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/shmercer/pairwiseLLM" class="external-link">pairwiseLLM</a></span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="live-comparisons">Live comparisons<a class="anchor" aria-label="anchor" href="#live-comparisons"></a>
</h2>
<p>Live pairwise comparisons (one-off or small batches) are available through a single, unified API:</p>
<ul>
<li><p><code><a href="reference/llm_compare_pair.html">llm_compare_pair()</a></code> – compare a single pair</p></li>
<li><p><code><a href="reference/submit_llm_pairs.html">submit_llm_pairs()</a></code> – submit many pairs in one call</p></li>
</ul>
<p>Backend-specific helpers (e.g., <code><a href="reference/submit_openai_pairs_live.html">submit_openai_pairs_live()</a></code>) are available but most users will only need the unified functions.</p>
</div>
<div class="section level2">
<h2 id="batch-comparisons">Batch comparisons<a class="anchor" aria-label="anchor" href="#batch-comparisons"></a>
</h2>
<p>Batch APIs (for larger jobs and offline processing) are implemented through a single, unified API:</p>
<ul>
<li><p><code><a href="reference/llm_submit_pairs_batch.html">llm_submit_pairs_batch()</a></code> — submit batch requests</p></li>
<li><p><code><a href="reference/llm_download_batch_results.html">llm_download_batch_results()</a></code> — download &amp; parse the completed results</p></li>
</ul>
<p>Each provider also has its own <code>build_*_batch_requests()</code>, <code>run_*_batch_pipeline()</code>, and <code>parse_*_batch_output()</code> functions.</p>
</div>
<div class="section level2">
<h2 id="api-keys">API Keys<a class="anchor" aria-label="anchor" href="#api-keys"></a>
</h2>
<p><code>pairwiseLLM</code> uses a CRAN-safe API key layer:</p>
<ul>
<li><p>Keys are read only from environment variables (e.g., <code>Sys.getenv("OPENAI_API_KEY")</code>).</p></li>
<li><p>Keys are never printed or stored in package data.</p></li>
<li><p>A single helper, <code>.get_api_key()</code>, is used internally by all backends.</p></li>
</ul>
<p>You can quickly verify what keys are visible to R using:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/check_llm_api_keys.html">check_llm_api_keys</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>This returns a tibble with one row per provider and a column indicating whether a key is set.</p>
</div>
<div class="section level2">
<h2 id="quick-start-example">Quick Start Example<a class="anchor" aria-label="anchor" href="#quick-start-example"></a>
</h2>
<p>Here is a minimal, end-to-end example using OpenAI via the unified API:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/shmercer/pairwiseLLM" class="external-link">pairwiseLLM</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 1. Load included writing sample data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"example_writing_samples"</span>, package <span class="op">=</span> <span class="st">"pairwiseLLM"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 2. Create a small set of pairs</span></span>
<span><span class="va">pairs</span> <span class="op">&lt;-</span> <span class="va">example_writing_samples</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/make_pairs.html">make_pairs</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/sample_pairs.html">sample_pairs</a></span><span class="op">(</span>n_pairs <span class="op">=</span> <span class="fl">5</span>, seed <span class="op">=</span> <span class="fl">321</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/randomize_pair_order.html">randomize_pair_order</a></span><span class="op">(</span>seed <span class="op">=</span> <span class="fl">654</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 3. Specify the trait and prompt template</span></span>
<span><span class="va">td</span>   <span class="op">&lt;-</span> <span class="fu"><a href="reference/trait_description.html">trait_description</a></span><span class="op">(</span><span class="st">"overall_quality"</span><span class="op">)</span></span>
<span><span class="va">tmpl</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/set_prompt_template.html">set_prompt_template</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 4. Submit to a backend (e.g., OpenAI)</span></span>
<span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/submit_llm_pairs.html">submit_llm_pairs</a></span><span class="op">(</span></span>
<span>  pairs             <span class="op">=</span> <span class="va">pairs</span>,</span>
<span>  model             <span class="op">=</span> <span class="st">"gpt-4o"</span>,</span>
<span>  trait_name        <span class="op">=</span> <span class="va">td</span><span class="op">$</span><span class="va">name</span>,</span>
<span>  trait_description <span class="op">=</span> <span class="va">td</span><span class="op">$</span><span class="va">description</span>,</span>
<span>  prompt_template   <span class="op">=</span> <span class="va">tmpl</span>,</span>
<span>  backend           <span class="op">=</span> <span class="st">"openai"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 5. Fit a Bradley–Terry model</span></span>
<span><span class="va">bt_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/build_bt_data.html">build_bt_data</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span><span class="va">bt_fit</span>  <span class="op">&lt;-</span> <span class="fu"><a href="reference/fit_bt_model.html">fit_bt_model</a></span><span class="op">(</span><span class="va">bt_data</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="reference/summarize_bt_fit.html">summarize_bt_fit</a></span><span class="op">(</span><span class="va">bt_fit</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="default-prompt-template-positional-bias-tested">Default Prompt Template (Positional-Bias Tested)<a class="anchor" aria-label="anchor" href="#default-prompt-template-positional-bias-tested"></a>
</h2>
<p><code>pairwiseLLM</code> ships with a default XML-style prompt template that has been tested across:</p>
<ul>
<li><p>multiple OpenAI GPT models,</p></li>
<li><p>Anthropic Claude models, and</p></li>
<li><p>Google Gemini models.</p></li>
</ul>
<p>The default template is designed to:</p>
<ul>
<li><p>clearly separate instructions and samples</p></li>
<li><p>use explicit <code>&lt;SAMPLE_1&gt;</code>, <code>&lt;SAMPLE_2&gt;</code>, and <code>&lt;BETTER_SAMPLE&gt;</code> tags</p></li>
<li><p>minimize positional and formatting bias</p></li>
<li><p>avoid returning chain-of-thought unless explicitly requested</p></li>
</ul>
<p>You can retrieve or inspect the default template from R:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">default_template</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/set_prompt_template.html">set_prompt_template</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="va">default_template</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>You are an expert writing assessor.</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>Your task is to decide which of two student writing samples shows BETTER {TRAIT_NAME}.</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>Definition of {TRAIT_NAME}<span class="sc">:</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>{TRAIT_DESCRIPTION}</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>INSTRUCTIONS<span class="sc">:</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="fl">1.</span> Read BOTH samples carefully.</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="fl">2.</span> Evaluate the samples ONLY on {TRAIT_NAME}, according to the definition above.</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>   Do NOT consider length, formatting, grammar, topic relevance, or any other</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>   aspect unless it directly affects {TRAIT_NAME}.</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="fl">3.</span> The labels SAMPLE_1 and SAMPLE_2 are arbitrary. They do NOT indicate quality.</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>   SAMPLE_1 could have been SAMPLE_2 and vice versa.</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a><span class="dv">3</span>a. Before deciding, remind yourself explicitly that SAMPLE_1 and SAMPLE_2 might</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>    have been presented <span class="cf">in</span> the opposite order. Your decision MUST NOT depend on</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>    their position.</span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a><span class="dv">3</span>b. After reading both samples, PAUSE and reconsider which sample is truly better</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>    on {TRAIT_NAME}, independent of position.</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a><span class="fl">4.</span> You MUST choose exactly one sample. If the samples seem equal, choose the one</span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a>   that is even slightly better on {TRAIT_NAME}. Do NOT output ties.</span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a><span class="fl">5.</span> Decide which sample has BETTER QUALITY on {TRAIT_NAME}.</span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a>   Think silently. Do NOT reveal your reasoning.</span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a><span class="fl">6.</span> After making your judgment, respond EXACTLY with ONE of the following lines<span class="sc">:</span></span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a>   <span class="er">&lt;</span>BETTER_SAMPLE<span class="sc">&gt;</span>SAMPLE_1<span class="sc">&lt;</span><span class="er">/</span>BETTER_SAMPLE<span class="sc">&gt;</span></span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>   OR</span>
<span id="cb6-36"><a href="#cb6-36" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" tabindex="-1"></a>   <span class="sc">&lt;</span>BETTER_SAMPLE<span class="sc">&gt;</span>SAMPLE_2<span class="sc">&lt;</span><span class="er">/</span>BETTER_SAMPLE<span class="sc">&gt;</span></span>
<span id="cb6-38"><a href="#cb6-38" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" tabindex="-1"></a><span class="dv">6</span>a. Before responding, VERIFY that the tag you are about to output matches</span>
<span id="cb6-40"><a href="#cb6-40" tabindex="-1"></a>    your internal decision about which sample is better.</span>
<span id="cb6-41"><a href="#cb6-41" tabindex="-1"></a></span>
<span id="cb6-42"><a href="#cb6-42" tabindex="-1"></a>IMPORTANT<span class="sc">:</span></span>
<span id="cb6-43"><a href="#cb6-43" tabindex="-1"></a><span class="sc">-</span> Output EXACTLY one of the two lines above.</span>
<span id="cb6-44"><a href="#cb6-44" tabindex="-1"></a><span class="sc">-</span> Do NOT add explanations, reasoning, punctuation, or extra text.</span>
<span id="cb6-45"><a href="#cb6-45" tabindex="-1"></a><span class="sc">-</span> Do NOT include chain<span class="sc">-</span>of<span class="sc">-</span>thought or justification.</span>
<span id="cb6-46"><a href="#cb6-46" tabindex="-1"></a></span>
<span id="cb6-47"><a href="#cb6-47" tabindex="-1"></a>SAMPLE <span class="dv">1</span><span class="sc">:</span></span>
<span id="cb6-48"><a href="#cb6-48" tabindex="-1"></a>{SAMPLE_1}</span>
<span id="cb6-49"><a href="#cb6-49" tabindex="-1"></a></span>
<span id="cb6-50"><a href="#cb6-50" tabindex="-1"></a>SAMPLE <span class="dv">2</span><span class="sc">:</span></span>
<span id="cb6-51"><a href="#cb6-51" tabindex="-1"></a>{SAMPLE_2}</span></code></pre></div>
<p>You can supply your own template globally:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/set_prompt_template.html">set_prompt_template</a></span><span class="op">(</span><span class="va">my_custom_template</span><span class="op">)</span></span></code></pre></div>
<p>or switch templates within a session as needed.</p>
</div>
<div class="section level2">
<h2 id="positional-bias-testing">Positional Bias Testing<a class="anchor" aria-label="anchor" href="#positional-bias-testing"></a>
</h2>
<p>LLMs often show a preference for the first or second position when making pairwise judgments. <code>pairwiseLLM</code> includes built-in tools to quantify and diagnose positional bias.</p>
<div class="section level3">
<h3 id="workflow">Workflow<a class="anchor" aria-label="anchor" href="#workflow"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Create base pairs</li>
</ol>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pairs</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/make_pairs.html">make_pairs</a></span><span class="op">(</span><span class="va">items</span><span class="op">)</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Create reversed pairs</li>
</ol>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rev_pairs</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/sample_reverse_pairs.html">sample_reverse_pairs</a></span><span class="op">(</span><span class="va">pairs</span><span class="op">)</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Submit both sets to a backend</li>
</ol>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res_forward</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/submit_llm_pairs.html">submit_llm_pairs</a></span><span class="op">(</span></span>
<span>  <span class="va">pairs</span>,</span>
<span>  backend <span class="op">=</span> <span class="st">"openai"</span>,</span>
<span>  model <span class="op">=</span> <span class="st">"gpt-4o"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">res_reversed</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/submit_llm_pairs.html">submit_llm_pairs</a></span><span class="op">(</span></span>
<span>  <span class="va">rev_pairs</span>,</span>
<span>  backend <span class="op">=</span> <span class="st">"openai"</span>,</span>
<span>  model <span class="op">=</span> <span class="st">"gpt-4o"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li>Run the positional bias diagnostic</li>
</ol>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bias</span> <span class="op">&lt;-</span> <span class="fu">test_positional_bias</span><span class="op">(</span><span class="va">res_forward</span>, <span class="va">res_reversed</span><span class="op">)</span></span>
<span><span class="va">bias</span></span></code></pre></div>
<p>Typical output includes:</p>
<ul>
<li><p>the proportion of consistent decisions between forward and reversed pairs</p></li>
<li><p>an estimate of positional bias (e.g., preference for “first” vs “second” position)</p></li>
<li><p>simple significance/comparison summaries</p></li>
</ul>
<p>This workflow works with any supported backend, so you can compare positional bias across providers and models.</p>
</div>
</div>
<div class="section level2">
<h2 id="positional-bias-of-default-template">Positional bias of default template<a class="anchor" aria-label="anchor" href="#positional-bias-of-default-template"></a>
</h2>
<p>For each model, we ran pairwise comparisons of overall quality (“Overall quality of the writing, considering how well ideas are expressed, how clearly the writing is organized, and how effective the language and conventions are.”) on all example essays in two orders:</p>
<ul>
<li><p>Forward: randomized assignment of SAMPLE_1 vs SAMPLE_2</p></li>
<li><p>Reverse: the same pairs with SAMPLE_1 and SAMPLE_2 swapped</p></li>
</ul>
<p>We then computed:</p>
<ul>
<li><p>Proportion consistent: The proportion of pairs where the model picks the same winner in both forward and reverse order.</p></li>
<li><p>Bias (p): The p-value from a binomial test evaluating if SAMPLE_1 wins more or less often than 50% of the time across all forward + reverse comparisons combined.</p></li>
</ul>
<table class="table">
<colgroup>
<col width="14%">
<col width="29%">
<col width="13%">
<col width="31%">
<col width="10%">
</colgroup>
<thead><tr class="header">
<th>provider</th>
<th>model</th>
<th>thinking</th>
<th>proportion_consistent</th>
<th>bias_p</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>anthropic</td>
<td>claude-haiku-4-5</td>
<td>No</td>
<td>0.933</td>
<td>0.766</td>
</tr>
<tr class="even">
<td>anthropic</td>
<td>claude-haiku-4-5</td>
<td>Yes</td>
<td>0.911</td>
<td>1.000</td>
</tr>
<tr class="odd">
<td>anthropic</td>
<td>claude-opus-4-0</td>
<td>No</td>
<td>0.978</td>
<td>0.371</td>
</tr>
<tr class="even">
<td>anthropic</td>
<td>claude-opus-4-0</td>
<td>Yes</td>
<td>0.933</td>
<td>0.371</td>
</tr>
<tr class="odd">
<td>anthropic</td>
<td>claude-opus-4-1</td>
<td>No</td>
<td>0.978</td>
<td>0.371</td>
</tr>
<tr class="even">
<td>anthropic</td>
<td>claude-opus-4-1</td>
<td>Yes</td>
<td>0.956</td>
<td>0.233</td>
</tr>
<tr class="odd">
<td>anthropic</td>
<td>claude-opus-4-5</td>
<td>No</td>
<td>0.867</td>
<td>1.000</td>
</tr>
<tr class="even">
<td>anthropic</td>
<td>claude-opus-4-5</td>
<td>Yes</td>
<td>0.844</td>
<td>1.000</td>
</tr>
<tr class="odd">
<td>anthropic</td>
<td>claude-sonnet-4-0</td>
<td>No</td>
<td>0.956</td>
<td>0.371</td>
</tr>
<tr class="even">
<td>anthropic</td>
<td>claude-sonnet-4-0</td>
<td>Yes</td>
<td>0.933</td>
<td>0.371</td>
</tr>
<tr class="odd">
<td>anthropic</td>
<td>claude-sonnet-4-5</td>
<td>No</td>
<td>0.933</td>
<td>0.551</td>
</tr>
<tr class="even">
<td>anthropic</td>
<td>claude-sonnet-4-5</td>
<td>Yes</td>
<td>0.956</td>
<td>0.551</td>
</tr>
<tr class="odd">
<td>gemini</td>
<td>gemini-3-pro-preview</td>
<td>Yes</td>
<td>0.978</td>
<td>0.233</td>
</tr>
<tr class="even">
<td>openai</td>
<td>gpt-4.1</td>
<td>No</td>
<td>0.867</td>
<td>0.766</td>
</tr>
<tr class="odd">
<td>openai</td>
<td>gpt-4.1-mini</td>
<td>No</td>
<td>0.844</td>
<td>0.766</td>
</tr>
<tr class="even">
<td>openai</td>
<td>gpt-4.1-nano</td>
<td>No</td>
<td>0.667</td>
<td>0.135</td>
</tr>
<tr class="odd">
<td>openai</td>
<td>gpt-4o</td>
<td>No</td>
<td>0.778</td>
<td>0.551</td>
</tr>
<tr class="even">
<td>openai</td>
<td>gpt-5.1</td>
<td>No</td>
<td>0.800</td>
<td>0.371</td>
</tr>
<tr class="odd">
<td>openai</td>
<td>gpt-5.1</td>
<td>Yes</td>
<td>0.800</td>
<td>0.551</td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="bradleyterry-modeling-ability-scores">Bradley–Terry Modeling (Ability Scores)<a class="anchor" aria-label="anchor" href="#bradleyterry-modeling-ability-scores"></a>
</h2>
<p><code>pairwiseLLM</code> provides a modeling layer to convert LLM pairwise comparison results into latent ability scores using Bradley–Terry models.</p>
<div class="section level3">
<h3 id="typical-workflow">Typical workflow<a class="anchor" aria-label="anchor" href="#typical-workflow"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Collect pairwise results</li>
</ol>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/submit_llm_pairs.html">submit_llm_pairs</a></span><span class="op">(</span></span>
<span>  <span class="va">pairs</span>,</span>
<span>  backend <span class="op">=</span> <span class="st">"openai"</span>,</span>
<span>  model <span class="op">=</span> <span class="st">"gpt-4o"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Build BT data</li>
</ol>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bt_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/build_bt_data.html">build_bt_data</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Fit the model</li>
</ol>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bt_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/fit_bt_model.html">fit_bt_model</a></span><span class="op">(</span><span class="va">bt_data</span><span class="op">)</span></span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li>Summarize results</li>
</ol>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">summary_tbl</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/summarize_bt_fit.html">summarize_bt_fit</a></span><span class="op">(</span><span class="va">bt_fit</span><span class="op">)</span></span>
<span><span class="va">summary_tbl</span></span></code></pre></div>
<p>Depending on configuration, the modeling layer supports:</p>
<ul>
<li><p>different engines (e.g., <code>sirt</code>, <code>BradleyTerry2</code>)</p></li>
<li><p>ability estimates with standard errors</p></li>
<li><p>ranking and comparison of items</p></li>
</ul>
<p>These functions turn raw pairwise outputs into interpretable rankings suitable for evaluation studies, benchmark construction, and research projects.</p>
</div>
</div>
<div class="section level2">
<h2 id="live-vs-batch-workflows">Live vs Batch Workflows<a class="anchor" aria-label="anchor" href="#live-vs-batch-workflows"></a>
</h2>
<div class="section level3">
<h3 id="live-interactive-usage">Live (interactive) usage<a class="anchor" aria-label="anchor" href="#live-interactive-usage"></a>
</h3>
<p>Best for smaller numbers of pairs or exploratory work:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pairs</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/make_pairs.html">make_pairs</a></span><span class="op">(</span><span class="va">items</span><span class="op">)</span></span>
<span></span>
<span><span class="va">res_live</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/submit_llm_pairs.html">submit_llm_pairs</a></span><span class="op">(</span></span>
<span>  <span class="va">pairs</span>,</span>
<span>  backend <span class="op">=</span> <span class="st">"anthropic"</span>,</span>
<span>  model <span class="op">=</span> <span class="st">"claude-sonnet-4-5"</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="batch-usage-large-jobs">Batch usage (large jobs)<a class="anchor" aria-label="anchor" href="#batch-usage-large-jobs"></a>
</h3>
<p>Best for large-scale runs via provider batch APIs:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Example flow – function names will depend on backend</span></span>
<span><span class="va">reqs</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/build_openai_batch_requests.html">build_openai_batch_requests</a></span><span class="op">(</span><span class="va">pairs</span><span class="op">)</span></span>
<span></span>
<span><span class="va">batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/run_openai_batch_pipeline.html">run_openai_batch_pipeline</a></span><span class="op">(</span></span>
<span>  requests <span class="op">=</span> <span class="va">reqs</span>,</span>
<span>  model    <span class="op">=</span> <span class="st">"gpt-4o-mini"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">res_batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/parse_openai_batch_output.html">parse_openai_batch_output</a></span><span class="op">(</span><span class="va">batch</span><span class="op">$</span><span class="va">batch_output_path</span><span class="op">)</span></span></code></pre></div>
<p>A unified batch front-end can also be used.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/llm_submit_pairs_batch.html">llm_submit_pairs_batch</a></span><span class="op">(</span></span>
<span>  provider <span class="op">=</span> <span class="st">"openai"</span>,        <span class="co"># "openai", "anthropic", or "gemini"</span></span>
<span>  model <span class="op">=</span> <span class="st">"gpt-4o-mini"</span>,      <span class="co"># or any supported model</span></span>
<span>  pairs <span class="op">=</span> <span class="va">pairs</span>,              <span class="co"># tibble of pairwise comparisons</span></span>
<span>  trait_name <span class="op">=</span> <span class="st">"overall_quality"</span>,</span>
<span>  trait_description <span class="op">=</span> <span class="st">"Overall writing quality."</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/llm_download_batch_results.html">llm_download_batch_results</a></span><span class="op">(</span><span class="va">batch</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="roadmap-high-level">Roadmap (High Level)<a class="anchor" aria-label="anchor" href="#roadmap-high-level"></a>
</h2>
<p>Planned / in-progress features include:</p>
<ul>
<li><p>Local backends (e.g., Ollama) for offline testing</p></li>
<li><p>Expanded documentation: vignettes, pkgdown site, and worked examples</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="contributing">Contributing<a class="anchor" aria-label="anchor" href="#contributing"></a>
</h2>
<p>Issues and pull requests are welcome. If you’re adding a new backend or modeling method, please include:</p>
<ul>
<li><p>unit tests</p></li>
<li><p>example usage</p></li>
<li><p>documentation updates (including README / vignettes)</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="license">License<a class="anchor" aria-label="anchor" href="#license"></a>
</h2>
<p><code>pairwiseLLM</code> is released under the MIT License. See the <code>LICENSE</code> file for details.</p>
</div>
<div class="section level2">
<h2 id="package-author-and-maintainer">Package Author and Maintainer<a class="anchor" aria-label="anchor" href="#package-author-and-maintainer"></a>
</h2>
<ul>
<li>
<strong>Sterett H. Mercer</strong> - <em>University of British Columbia</em><br>
UBC Faculty Profile: <a href="https://ecps.educ.ubc.ca/sterett-h-mercer/" class="external-link uri">https://ecps.educ.ubc.ca/sterett-h-mercer/</a><br>
ResearchGate: <a href="https://www.researchgate.net/profile/Sterett_Mercer" class="external-link uri">https://www.researchgate.net/profile/Sterett_Mercer</a><br>
Google Scholar: <a href="https://scholar.google.ca/citations?user=YJg4svsAAAAJ&amp;hl=en" class="external-link uri">https://scholar.google.ca/citations?user=YJg4svsAAAAJ&amp;hl=en</a>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="citation">Citation<a class="anchor" aria-label="anchor" href="#citation"></a>
</h2>
<p>A formal <code>CITATION</code> file will be added prior to the first CRAN release.</p>
<p>In the meantime, if you use <code>pairwiseLLM</code> in published work, you can cite it as:</p>
<blockquote>
<p>Mercer, S. H. (2025). <em>pairwiseLLM: Pairwise comparisons of writing quality with LLMs</em> (R package). GitHub: <a href="https://github.com/shmercer/pairwiseLLM" class="external-link uri">https://github.com/shmercer/pairwiseLLM</a></p>
</blockquote>
</div>
</div>
  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/shmercer/pairwiseLLM/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/shmercer/pairwiseLLM/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small><a href="https://opensource.org/licenses/mit-license.php" class="external-link">MIT</a> + file <a href="LICENSE-text.html">LICENSE</a></small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing pairwiseLLM</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Sterett H. Mercer <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-7940-4221" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a>  </li>
</ul>
</div>

<div class="dev-status">
<h2 data-toc-skip>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/shmercer/pairwiseLLM/actions/workflows/R-CMD-check.yaml" class="external-link"><img src="https://github.com/shmercer/pairwiseLLM/actions/workflows/R-CMD-check.yaml/badge.svg" alt="R-CMD-check"></a></li>
<li><a href="https://app.codecov.io/gh/shmercer/pairwiseLLM" class="external-link"><img src="https://codecov.io/gh/shmercer/pairwiseLLM/graph/badge.svg" alt="Codecov test coverage"></a></li>
<li><a href="https://CRAN.R-project.org/package=pairwiseLLM" class="external-link"><img src="https://www.r-pkg.org/badges/version/pairwiseLLM" alt="CRAN status"></a></li>
<li><a href="https://github.com/shmercer/pairwiseLLM/blob/master/LICENSE.md" class="external-link"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License: MIT"></a></li>
</ul>
</div>

  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Sterett H. Mercer.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>

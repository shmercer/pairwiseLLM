<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Pairwise Comparison Tools for Large Language Model-Based Writing Evaluation • pairwiseLLM</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Pairwise Comparison Tools for Large Language Model-Based Writing Evaluation">
<meta name="description" content="Provides a unified framework for generating, submitting, and analyzing pairwise comparisons of writing quality using large language models (LLMs). The package supports live and/or batch evaluation workflows across multiple providers (`OpenAI`, `Anthropic`, `Google Gemini`, `Together AI`, and locally-hosted `Ollama` models), includes bias-tested prompt templates and a flexible template registry, and offers tools for constructing forward and reversed comparison sets to analyze consistency and positional bias. Results can be modeled using Bradley–Terry or Elo rating methods to derive writing quality scores.">
<meta property="og:description" content="Provides a unified framework for generating, submitting, and analyzing pairwise comparisons of writing quality using large language models (LLMs). The package supports live and/or batch evaluation workflows across multiple providers (`OpenAI`, `Anthropic`, `Google Gemini`, `Together AI`, and locally-hosted `Ollama` models), includes bias-tested prompt templates and a flexible template registry, and offers tools for constructing forward and reversed comparison sets to analyze consistency and positional bias. Results can be modeled using Bradley–Terry or Elo rating methods to derive writing quality scores.">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">pairwiseLLM</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="articles/advanced-batch-workflows.html">Advanced: Submitting and Polling Multiple Batches</a></li>
    <li><a class="dropdown-item" href="articles/getting-started.html">Getting Started with pairwiseLLM</a></li>
    <li><a class="dropdown-item" href="articles/prompt-template-positional-bias.html">Prompt Template Positional Bias Testing</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/shmercer/pairwiseLLM/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><p>pairwiseLLM: Pairwise Comparison Tools for Large Language Model-Based Writing Evaluation ================</p>
<!-- badges: start -->

<p><code>pairwiseLLM</code> provides a unified, extensible framework for generating, submitting, and modeling <strong>pairwise comparisons of writing quality</strong> using large language models (LLMs).</p>
<p>It includes:</p>
<ul>
<li>Unified <strong>live</strong> and <strong>batch</strong> APIs across OpenAI, Anthropic, and Gemini<br>
</li>
<li>A prompt template registry with <strong>tested templates</strong> designed to reduce positional bias<br>
</li>
<li>Positional-bias diagnostics (forward vs reverse design)<br>
</li>
<li>Bradley–Terry (BT) and Elo modeling<br>
</li>
<li>Consistent data structures for all providers</li>
</ul>
<hr>
<div class="section level2">
<h2 id="vignettes">Vignettes<a class="anchor" aria-label="anchor" href="#vignettes"></a>
</h2>
<p>Several vignettes are available to demonstrate functionality.</p>
<p>For basic function usage, see:</p>
<ul>
<li><a href="https://shmercer.github.io/pairwiseLLM/articles/getting-started.html"><code>vignette("getting-started")</code></a></li>
</ul>
<p>For advanced batch processing workflows, see:</p>
<ul>
<li><a href="https://shmercer.github.io/pairwiseLLM/articles/advanced-batch-workflows.html"><code>vignette("advanced-batch-workflows")</code></a></li>
</ul>
<p>For information on prompt evaluation and positional-bias diagnostics, see:</p>
<ul>
<li><a href="https://shmercer.github.io/pairwiseLLM/articles/prompt-template-positional-bias.html"><code>vignette("prompt-template-positional-bias")</code></a></li>
</ul>
<hr>
</div>
<div class="section level2">
<h2 id="supported-models">Supported Models<a class="anchor" aria-label="anchor" href="#supported-models"></a>
</h2>
<p>The following models are confirmed to work for pairwise comparisons:</p>
<table class="table">
<colgroup>
<col width="33%">
<col width="33%">
<col width="33%">
</colgroup>
<thead><tr class="header">
<th>Provider</th>
<th>Model</th>
<th>Reasoning Mode?</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong><a href="https://openai.com/api/" class="external-link">OpenAI</a></strong></td>
<td>gpt-5.1</td>
<td>✅ Yes</td>
</tr>
<tr class="even">
<td><strong><a href="https://openai.com/api/" class="external-link">OpenAI</a></strong></td>
<td>gpt-4o</td>
<td>❌ No</td>
</tr>
<tr class="odd">
<td><strong><a href="https://openai.com/api/" class="external-link">OpenAI</a></strong></td>
<td>gpt-4.1</td>
<td>❌ No</td>
</tr>
<tr class="even">
<td><strong><a href="https://console.anthropic.com/" class="external-link">Anthropic</a></strong></td>
<td>claude-sonnet-4-5</td>
<td>✅ Yes</td>
</tr>
<tr class="odd">
<td><strong><a href="https://console.anthropic.com/" class="external-link">Anthropic</a></strong></td>
<td>claude-haiku-4-5</td>
<td>✅ Yes</td>
</tr>
<tr class="even">
<td><strong><a href="https://console.anthropic.com/" class="external-link">Anthropic</a></strong></td>
<td>claude-opus-4-5</td>
<td>✅ Yes</td>
</tr>
<tr class="odd">
<td><strong><a href="https://aistudio.google.com/" class="external-link">Google/Gemini</a></strong></td>
<td>gemini-3-pro-preview</td>
<td>✅ Yes</td>
</tr>
<tr class="even">
<td><strong><a href="https://www.deepseek.com/en" class="external-link">DeepSeek-AI</a><sub>1</sub></strong></td>
<td>DeepSeek-R1</td>
<td>✅ Yes</td>
</tr>
<tr class="odd">
<td><strong><a href="https://www.deepseek.com/en" class="external-link">DeepSeek-AI</a><sub>1</sub></strong></td>
<td>DeepSeek-V3</td>
<td>❌ No</td>
</tr>
<tr class="even">
<td><strong><a href="https://www.moonshot.ai/" class="external-link">Moonshot-AI</a><sub>1</sub></strong></td>
<td>Kimi-K2-Instruct-0905</td>
<td>❌ No</td>
</tr>
<tr class="odd">
<td><strong><a href="https://qwen.ai/home" class="external-link">Qwen</a><sub>1</sub></strong></td>
<td>Qwen3-235B-A22B-Instruct-2507</td>
<td>❌ No</td>
</tr>
<tr class="even">
<td><strong><a href="https://qwen.ai/home" class="external-link">Qwen</a><sub>2</sub></strong></td>
<td>qwen3:32b</td>
<td>✅ Yes</td>
</tr>
<tr class="odd">
<td><strong><a href="https://deepmind.google/models/gemma/" class="external-link">Google</a><sub>2</sub></strong></td>
<td>gemma3:27b</td>
<td>❌ No</td>
</tr>
<tr class="even">
<td><strong><a href="https://mistral.ai/" class="external-link">Mistral</a><sub>2</sub></strong></td>
<td>mistral-small3.2:24b</td>
<td>❌ No</td>
</tr>
</tbody>
</table>
<p><sub>1</sub> via the <a href="https://www.together.ai/" class="external-link">together.ai</a> API</p>
<p><sub>2</sub> via <a href="https://ollama.com/" class="external-link">Ollama</a> on a local machine</p>
<p>Batch APIs are currently available for OpenAI, Anthropic, and Gemini only. Models accessed via Together.ai and Ollama are supported for live comparisons via <code><a href="reference/submit_llm_pairs.html">submit_llm_pairs()</a></code> / <code><a href="reference/llm_compare_pair.html">llm_compare_pair()</a></code>.</p>
<table class="table">
<thead><tr class="header">
<th>Backend</th>
<th>Live</th>
<th>Batch</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>openai</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr class="even">
<td>anthropic</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr class="odd">
<td>gemini</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr class="even">
<td>together</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr class="odd">
<td>ollama</td>
<td>✅</td>
<td>❌</td>
</tr>
</tbody>
</table>
<hr>
</div>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>Once the package is available on CRAN, install with:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"pairwiseLLM"</span><span class="op">)</span></span></code></pre></div>
<p>To install the development version from GitHub:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install.packages("pak")</span></span>
<span><span class="fu">pak</span><span class="fu">::</span><span class="fu"><a href="https://pak.r-lib.org/reference/pak.html" class="external-link">pak</a></span><span class="op">(</span><span class="st">"shmercer/pairwiseLLM"</span><span class="op">)</span></span></code></pre></div>
<p>Load the package:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/shmercer/pairwiseLLM" class="external-link">pairwiseLLM</a></span><span class="op">)</span></span></code></pre></div>
<hr>
</div>
<div class="section level2">
<h2 id="core-concepts">Core Concepts<a class="anchor" aria-label="anchor" href="#core-concepts"></a>
</h2>
<p>At a high level, <code>pairwiseLLM</code> workflows follow this structure:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Writing samples</strong> – e.g., essays, constructed responses, short answers.<br>
</li>
<li>
<strong>Trait</strong> – a rating dimension such as “overall quality” or “organization”.<br>
</li>
<li>
<strong>Pairs</strong> – pairs of samples to be compared for that trait.<br>
</li>
<li>
<strong>Prompt template</strong> – instructions + placeholders for <code>{TRAIT_NAME}</code>, <code>{TRAIT_DESCRIPTION}</code>, <code>{SAMPLE_1}</code>, <code>{SAMPLE_2}</code>.<br>
</li>
<li>
<strong>Backend</strong> – which provider/model to use (OpenAI, Anthropic, Gemini, Together, Ollama).<br>
</li>
<li>
<strong>Modeling</strong> – convert pairwise results to latent scores via BT or Elo.</li>
</ol>
<p>The package provides helpers for each step.</p>
<hr>
</div>
<div class="section level2">
<h2 id="live-comparisons">Live Comparisons<a class="anchor" aria-label="anchor" href="#live-comparisons"></a>
</h2>
<p>Use the unified API:</p>
<ul>
<li>
<code><a href="reference/llm_compare_pair.html">llm_compare_pair()</a></code> — compare one pair<br>
</li>
<li>
<code><a href="reference/submit_llm_pairs.html">submit_llm_pairs()</a></code> — compare many pairs at once</li>
</ul>
<p>Example:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"example_writing_samples"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pairs</span> <span class="op">&lt;-</span> <span class="va">example_writing_samples</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/make_pairs.html">make_pairs</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/sample_pairs.html">sample_pairs</a></span><span class="op">(</span><span class="fl">5</span>, seed <span class="op">=</span> <span class="fl">123</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/randomize_pair_order.html">randomize_pair_order</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">td</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/trait_description.html">trait_description</a></span><span class="op">(</span><span class="st">"overall_quality"</span><span class="op">)</span></span>
<span><span class="va">tmpl</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/get_prompt_template.html">get_prompt_template</a></span><span class="op">(</span><span class="st">"default"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/submit_llm_pairs.html">submit_llm_pairs</a></span><span class="op">(</span></span>
<span>  pairs             <span class="op">=</span> <span class="va">pairs</span>,</span>
<span>  backend           <span class="op">=</span> <span class="st">"openai"</span>,</span>
<span>  model             <span class="op">=</span> <span class="st">"gpt-4o"</span>,</span>
<span>  trait_name        <span class="op">=</span> <span class="va">td</span><span class="op">$</span><span class="va">name</span>,</span>
<span>  trait_description <span class="op">=</span> <span class="va">td</span><span class="op">$</span><span class="va">description</span>,</span>
<span>  prompt_template   <span class="op">=</span> <span class="va">tmpl</span></span>
<span><span class="op">)</span></span></code></pre></div>
<hr>
</div>
<div class="section level2">
<h2 id="batch-comparisons">Batch Comparisons<a class="anchor" aria-label="anchor" href="#batch-comparisons"></a>
</h2>
<p>Large-scale runs use:</p>
<ul>
<li>
<code><a href="reference/llm_submit_pairs_batch.html">llm_submit_pairs_batch()</a></code><br>
</li>
<li><code><a href="reference/llm_download_batch_results.html">llm_download_batch_results()</a></code></li>
</ul>
<p>Example:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/llm_submit_pairs_batch.html">llm_submit_pairs_batch</a></span><span class="op">(</span></span>
<span>  backend           <span class="op">=</span> <span class="st">"anthropic"</span>,</span>
<span>  model             <span class="op">=</span> <span class="st">"claude-sonnet-4-5"</span>,</span>
<span>  pairs             <span class="op">=</span> <span class="va">pairs</span>,</span>
<span>  trait_name        <span class="op">=</span> <span class="va">td</span><span class="op">$</span><span class="va">name</span>,</span>
<span>  trait_description <span class="op">=</span> <span class="va">td</span><span class="op">$</span><span class="va">description</span>,</span>
<span>  prompt_template   <span class="op">=</span> <span class="va">tmpl</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/llm_download_batch_results.html">llm_download_batch_results</a></span><span class="op">(</span><span class="va">batch</span><span class="op">)</span></span></code></pre></div>
<hr>
</div>
<div class="section level2">
<h2 id="api-keys">API Keys<a class="anchor" aria-label="anchor" href="#api-keys"></a>
</h2>
<p><code>pairwiseLLM</code> reads keys <strong>only from environment variables</strong>.<br>
Keys are <strong>never printed</strong>, <strong>never stored</strong>, and <strong>never written</strong> to disk.</p>
<p>You can verify which providers are available using:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/check_llm_api_keys.html">check_llm_api_keys</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>This returns a tibble showing whether R can see the required keys for:</p>
<ul>
<li>OpenAI<br>
</li>
<li>Anthropic<br>
</li>
<li>Google Gemini</li>
<li>Together.ai</li>
</ul>
<div class="section level3">
<h3 id="setting-api-keys">Setting API Keys<a class="anchor" aria-label="anchor" href="#setting-api-keys"></a>
</h3>
<p>You may set keys <strong>temporarily</strong> for the current R session:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.setenv</a></span><span class="op">(</span>OPENAI_API_KEY <span class="op">=</span> <span class="st">"your-key-here"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.setenv</a></span><span class="op">(</span>ANTHROPIC_API_KEY <span class="op">=</span> <span class="st">"your-key-here"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.setenv</a></span><span class="op">(</span>GEMINI_API_KEY <span class="op">=</span> <span class="st">"your-key-here"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.setenv</a></span><span class="op">(</span>TOGETHER_API_KEY <span class="op">=</span> <span class="st">"your-key-here"</span><span class="op">)</span></span></code></pre></div>
<p>…but for normal use and for reproducible analyses, it is <strong>strongly recommended</strong><br>
to store them in your <code>~/.Renviron</code> file.</p>
</div>
<div class="section level3">
<h3 id="recommended-method-adding-keys-to-renviron">Recommended method: Adding keys to <code>~/.Renviron</code>
<a class="anchor" aria-label="anchor" href="#recommended-method-adding-keys-to-renviron"></a>
</h3>
<p>Open your <code>.Renviron</code> file:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">usethis</span><span class="fu">::</span><span class="fu">edit_r_environ</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>Add the following lines:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>OPENAI_API_KEY<span class="ot">=</span><span class="st">"your-openai-key"</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>ANTHROPIC_API_KEY<span class="ot">=</span><span class="st">"your-anthropic-key"</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>GEMINI_API_KEY<span class="ot">=</span><span class="st">"your-gemini-key"</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>TOGETHER_API_KEY<span class="ot">=</span><span class="st">"your-together-key"</span></span></code></pre></div>
<p>Save the file, then restart R.</p>
<p>You can confirm that R now sees the keys:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/check_llm_api_keys.html">check_llm_api_keys</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<hr>
</div>
</div>
<div class="section level2">
<h2 id="prompt-templates--registry">Prompt Templates &amp; Registry<a class="anchor" aria-label="anchor" href="#prompt-templates--registry"></a>
</h2>
<p><code>pairwiseLLM</code> includes:</p>
<ul>
<li>A <strong>default template</strong> tested for positional bias<br>
</li>
<li>Support for <strong>multiple templates stored by name</strong><br>
</li>
<li>User-defined templates via <code><a href="reference/register_prompt_template.html">register_prompt_template()</a></code>
</li>
</ul>
<div class="section level3">
<h3 id="view-available-templates">View available templates<a class="anchor" aria-label="anchor" href="#view-available-templates"></a>
</h3>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/list_prompt_templates.html">list_prompt_templates</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "default" "test1"   "test2"   "test3"   "test4"   "test5"</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="show-the-default-template-truncated">Show the default template (truncated)<a class="anchor" aria-label="anchor" href="#show-the-default-template-truncated"></a>
</h3>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tmpl</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/get_prompt_template.html">get_prompt_template</a></span><span class="op">(</span><span class="st">"default"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/substr.html" class="external-link">substr</a></span><span class="op">(</span><span class="va">tmpl</span>, <span class="fl">1</span>, <span class="fl">400</span><span class="op">)</span>, <span class="st">"...\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; You are a debate adjudicator. Your task is to weigh the comparative strengths of two writing samples regarding a specific trait.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; TRAIT: {TRAIT_NAME}</span></span>
<span><span class="co">#&gt; DEFINITION: {TRAIT_DESCRIPTION}</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; SAMPLES:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; === SAMPLE_1 ===</span></span>
<span><span class="co">#&gt; {SAMPLE_1}</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; === SAMPLE_2 ===</span></span>
<span><span class="co">#&gt; {SAMPLE_2}</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; EVALUATION PROCESS (Mental Simulation):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1.  **Advocate for SAMPLE_1**: Mentally list the single strongest point of evidence that makes SAMPLE_1 the  ...</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="register-your-own-template">Register your own template<a class="anchor" aria-label="anchor" href="#register-your-own-template"></a>
</h3>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/register_prompt_template.html">register_prompt_template</a></span><span class="op">(</span><span class="st">"my_template"</span>, <span class="st">"</span></span>
<span><span class="st">Compare two essays for {TRAIT_NAME}…</span></span>
<span><span class="st"></span></span>
<span><span class="st">{TRAIT_NAME} is defined as {TRAIT_DESCRIPTION}.</span></span>
<span><span class="st"></span></span>
<span><span class="st">SAMPLE 1:</span></span>
<span><span class="st">{SAMPLE_1}</span></span>
<span><span class="st"></span></span>
<span><span class="st">SAMPLE 2:</span></span>
<span><span class="st">{SAMPLE_2}</span></span>
<span><span class="st"></span></span>
<span><span class="st">&lt;BETTER_SAMPLE&gt;SAMPLE_1&lt;/BETTER_SAMPLE&gt; or</span></span>
<span><span class="st">&lt;BETTER_SAMPLE&gt;SAMPLE_2&lt;/BETTER_SAMPLE&gt;</span></span>
<span><span class="st">"</span><span class="op">)</span></span></code></pre></div>
<p>Use it in a submission:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tmpl</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/get_prompt_template.html">get_prompt_template</a></span><span class="op">(</span><span class="st">"my_template"</span><span class="op">)</span></span></code></pre></div>
<hr>
</div>
</div>
<div class="section level2">
<h2 id="trait-descriptions">Trait Descriptions<a class="anchor" aria-label="anchor" href="#trait-descriptions"></a>
</h2>
<p>Traits define what “quality” means.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/trait_description.html">trait_description</a></span><span class="op">(</span><span class="st">"overall_quality"</span><span class="op">)</span></span>
<span><span class="co">#&gt; $name</span></span>
<span><span class="co">#&gt; [1] "Overall Quality"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $description</span></span>
<span><span class="co">#&gt; [1] "Overall quality of the writing, considering how well ideas are expressed,\n      how clearly the writing is organized, and how effective the language and\n      conventions are."</span></span></code></pre></div>
<p>You can also provide custom traits:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/trait_description.html">trait_description</a></span><span class="op">(</span></span>
<span>  custom_name        <span class="op">=</span> <span class="st">"Clarity"</span>,</span>
<span>  custom_description <span class="op">=</span> <span class="st">"How understandable, coherent, and well structured the ideas are."</span></span>
<span><span class="op">)</span></span></code></pre></div>
<hr>
</div>
<div class="section level2">
<h2 id="positional-bias-testing">Positional Bias Testing<a class="anchor" aria-label="anchor" href="#positional-bias-testing"></a>
</h2>
<p>LLMs often show a first-position or second-position bias.<br><code>pairwiseLLM</code> includes explicit tools for testing this.</p>
<div class="section level3">
<h3 id="typical-workflow">Typical workflow<a class="anchor" aria-label="anchor" href="#typical-workflow"></a>
</h3>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pairs_fwd</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/make_pairs.html">make_pairs</a></span><span class="op">(</span><span class="va">example_writing_samples</span><span class="op">)</span></span>
<span><span class="va">pairs_rev</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/sample_reverse_pairs.html">sample_reverse_pairs</a></span><span class="op">(</span><span class="va">pairs_fwd</span>, reverse_pct <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span></span></code></pre></div>
<p>Submit:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res_fwd</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/submit_llm_pairs.html">submit_llm_pairs</a></span><span class="op">(</span><span class="va">pairs_fwd</span>, model <span class="op">=</span> <span class="st">"gpt-4o"</span>, backend <span class="op">=</span> <span class="st">"openai"</span>, <span class="va">...</span><span class="op">)</span></span>
<span><span class="va">res_rev</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/submit_llm_pairs.html">submit_llm_pairs</a></span><span class="op">(</span><span class="va">pairs_rev</span>, model <span class="op">=</span> <span class="st">"gpt-4o"</span>, backend <span class="op">=</span> <span class="st">"openai"</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
<p>Compute bias:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cons</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/compute_reverse_consistency.html">compute_reverse_consistency</a></span><span class="op">(</span><span class="va">res_fwd</span>, <span class="va">res_rev</span><span class="op">)</span></span>
<span><span class="va">bias</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/check_positional_bias.html">check_positional_bias</a></span><span class="op">(</span><span class="va">cons</span><span class="op">)</span></span>
<span></span>
<span><span class="va">cons</span><span class="op">$</span><span class="va">summary</span></span>
<span><span class="va">bias</span><span class="op">$</span><span class="va">summary</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="positional-bias-tested-templates">Positional-bias tested templates<a class="anchor" aria-label="anchor" href="#positional-bias-tested-templates"></a>
</h3>
<p>Five included templates have been tested across different backend providers. Complete details are presented in a vignette: <a href="https://shmercer.github.io/pairwiseLLM/articles/prompt-template-positional-bias.html"><code>vignette("prompt-template-positional-bias")</code></a></p>
<hr>
</div>
</div>
<div class="section level2">
<h2 id="bradleyterry--elo-modeling">Bradley–Terry &amp; Elo Modeling<a class="anchor" aria-label="anchor" href="#bradleyterry--elo-modeling"></a>
</h2>
<div class="section level3">
<h3 id="bradleyterry-bt">Bradley–Terry (BT)<a class="anchor" aria-label="anchor" href="#bradleyterry-bt"></a>
</h3>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bt_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/build_bt_data.html">build_bt_data</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span><span class="va">bt_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/fit_bt_model.html">fit_bt_model</a></span><span class="op">(</span><span class="va">bt_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="reference/summarize_bt_fit.html">summarize_bt_fit</a></span><span class="op">(</span><span class="va">bt_fit</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="elo-modeling">Elo Modeling<a class="anchor" aria-label="anchor" href="#elo-modeling"></a>
</h3>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># res: output from submit_llm_pairs() / llm_submit_pairs_batch()</span></span>
<span><span class="va">elo_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/build_elo_data.html">build_elo_data</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span><span class="va">elo_fit</span>  <span class="op">&lt;-</span> <span class="fu"><a href="reference/fit_elo_model.html">fit_elo_model</a></span><span class="op">(</span><span class="va">elo_data</span>, runs <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">elo_fit</span><span class="op">$</span><span class="va">elo</span></span>
<span><span class="va">elo_fit</span><span class="op">$</span><span class="va">reliability</span></span>
<span><span class="va">elo_fit</span><span class="op">$</span><span class="va">reliability_weighted</span></span></code></pre></div>
<hr>
</div>
</div>
<div class="section level2">
<h2 id="live-vs-batch-summary">Live vs Batch Summary<a class="anchor" aria-label="anchor" href="#live-vs-batch-summary"></a>
</h2>
<table class="table">
<colgroup>
<col width="33%">
<col width="33%">
<col width="33%">
</colgroup>
<thead><tr class="header">
<th>Workflow</th>
<th>Use Case</th>
<th>Functions</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Live</strong></td>
<td>small or interactive runs</td>
<td>
<code>submit_llm_pairs</code>, <code>llm_compare_pair</code>
</td>
</tr>
<tr class="even">
<td><strong>Batch</strong></td>
<td>large jobs, cost control</td>
<td>
<code>llm_submit_pairs_batch</code>, <code>llm_download_batch_results</code>
</td>
</tr>
</tbody>
</table>
<hr>
</div>
<div class="section level2">
<h2 id="contributing">Contributing<a class="anchor" aria-label="anchor" href="#contributing"></a>
</h2>
<p>Contributions to <strong>pairwiseLLM</strong> are very welcome!</p>
<ul>
<li>Bug reports (with reproducible examples when possible)</li>
<li>Feature requests, ideas, and discussion</li>
<li>Pull requests improving:
<ul>
<li>functionality</li>
<li>documentation</li>
<li>examples / vignettes</li>
<li>test coverage</li>
</ul>
</li>
<li>Backend integrations (e.g., additional LLM providers or local inference engines)</li>
<li>Modeling extensions</li>
</ul>
</div>
<div class="section level2">
<h2 id="reporting-issues">Reporting issues<a class="anchor" aria-label="anchor" href="#reporting-issues"></a>
</h2>
<p>If you encounter a problem:</p>
<ol style="list-style-type: decimal">
<li>
<p>Run:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">devtools</span><span class="fu">::</span><span class="fu">session_info</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</li>
<li>
<p>Include:</p>
<ul>
<li>reproducible code</li>
<li>the error message</li>
<li>the model/backend involved</li>
<li>your operating system</li>
</ul>
</li>
<li><p>Open an issue at:<br><a href="https://github.com/shmercer/pairwiseLLM/issues" class="external-link uri">https://github.com/shmercer/pairwiseLLM/issues</a></p></li>
</ol>
<hr>
</div>
<div class="section level2">
<h2 id="license">License<a class="anchor" aria-label="anchor" href="#license"></a>
</h2>
<p>MIT License. See <code>LICENSE</code>.</p>
<hr>
</div>
<div class="section level2">
<h2 id="package-author-and-maintainer">Package Author and Maintainer<a class="anchor" aria-label="anchor" href="#package-author-and-maintainer"></a>
</h2>
<ul>
<li>
<strong>Sterett H. Mercer</strong> – <em>University of British Columbia</em><br>
UBC Faculty Profile: <a href="https://ecps.educ.ubc.ca/sterett-h-mercer/" class="external-link uri">https://ecps.educ.ubc.ca/sterett-h-mercer/</a><br>
ResearchGate: <a href="https://www.researchgate.net/profile/Sterett_Mercer/" class="external-link uri">https://www.researchgate.net/profile/Sterett_Mercer/</a><br>
Google Scholar: <a href="https://scholar.google.ca/citations?user=YJg4svsAAAAJ&amp;hl=en" class="external-link uri">https://scholar.google.ca/citations?user=YJg4svsAAAAJ&amp;hl=en</a>
</li>
</ul>
<hr>
</div>
<div class="section level2">
<h2 id="citation">Citation<a class="anchor" aria-label="anchor" href="#citation"></a>
</h2>
<blockquote>
<p>Mercer, S. H. (2025). pairwiseLLM: Pairwise writing quality comparisons with large language models (Version 1.0.0) [R package; Computer software]. <a href="https://github.com/shmercer/pairwiseLLM" class="external-link uri">https://github.com/shmercer/pairwiseLLM</a></p>
</blockquote>
</div>

  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/shmercer/pairwiseLLM/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/shmercer/pairwiseLLM/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small><a href="https://opensource.org/licenses/mit-license.php" class="external-link">MIT</a> + file <a href="LICENSE-text.html">LICENSE</a></small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing pairwiseLLM</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Sterett H. Mercer <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-7940-4221" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a>  </li>
</ul>
</div>

<div class="dev-status">
<h2 data-toc-skip>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/shmercer/pairwiseLLM/actions/workflows/R-CMD-check.yaml" class="external-link"><img src="https://github.com/shmercer/pairwiseLLM/actions/workflows/R-CMD-check.yaml/badge.svg" alt="R-CMD-check"></a></li>
<li><a href="https://app.codecov.io/gh/shmercer/pairwiseLLM" class="external-link"><img src="https://codecov.io/gh/shmercer/pairwiseLLM/graph/badge.svg" alt="Codecov test coverage"></a></li>
<li><a href="https://CRAN.R-project.org/package=pairwiseLLM" class="external-link"><img src="https://www.r-pkg.org/badges/version/pairwiseLLM" alt="CRAN status"></a></li>
<li><a href="https://github.com/shmercer/pairwiseLLM/blob/master/LICENSE.md" class="external-link"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License: MIT"></a></li>
</ul>
</div>

  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Sterett H. Mercer.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>

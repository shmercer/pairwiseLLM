% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/adaptive_rank.R
\name{make_adaptive_judge_llm}
\alias{make_adaptive_judge_llm}
\title{Build an LLM judge function for adaptive ranking}
\usage{
make_adaptive_judge_llm(
  backend = c("openai", "anthropic", "gemini", "together", "ollama"),
  model,
  trait = "overall_quality",
  trait_name = NULL,
  trait_description = NULL,
  prompt_template = set_prompt_template(),
  endpoint = "chat.completions",
  api_key = NULL,
  include_raw = FALSE,
  text_col = "text",
  judge_args = list()
)
}
\arguments{
\item{backend}{Backend passed to \code{\link[=llm_compare_pair]{llm_compare_pair()}}.}

\item{model}{Model identifier passed to \code{\link[=llm_compare_pair]{llm_compare_pair()}}.}

\item{trait}{Built-in trait key used when no custom trait is supplied.
Ignored when both \code{trait_name} and \code{trait_description} are supplied.}

\item{trait_name}{Optional custom trait display name.}

\item{trait_description}{Optional custom trait definition.}

\item{prompt_template}{Prompt template string. Defaults to
\code{\link[=set_prompt_template]{set_prompt_template()}}.}

\item{endpoint}{Endpoint family passed to \code{\link[=llm_compare_pair]{llm_compare_pair()}}.
Only used when \code{backend = "openai"}; ignored otherwise.}

\item{api_key}{Optional API key passed to \code{\link[=llm_compare_pair]{llm_compare_pair()}}.}

\item{include_raw}{Logical; forwarded to \code{\link[=llm_compare_pair]{llm_compare_pair()}}.}

\item{text_col}{Name of the text column expected in adaptive item rows.}

\item{judge_args}{Named list of additional fixed arguments forwarded to
\code{\link[=llm_compare_pair]{llm_compare_pair()}}. Use this for provider-specific controls such as
\code{reasoning}, \code{service_tier}, \code{temperature}, \code{top_p}, \code{logprobs}, \code{host},
or \code{include_thoughts}.}
}
\value{
A function \code{judge(A, B, state, ...)} returning a list with fields
\code{is_valid}, \code{Y}, and \code{invalid_reason}.
}
\description{
Creates a judge function compatible with \code{\link[=adaptive_rank_run_live]{adaptive_rank_run_live()}} by
wrapping \code{\link[=llm_compare_pair]{llm_compare_pair()}} and converting provider responses into
adaptive binary outcomes (\code{Y} in \verb{\{0,1\}}).
}
\details{
The returned function has signature \code{judge(A, B, state, ...)} and enforces
the adaptive transactional contract:
it returns \code{is_valid = TRUE} with \code{Y} in \verb{\{0,1\}} when the model response
identifies one of the two presented items, and returns \code{is_valid = FALSE}
otherwise.

Model configuration is split into:
\itemize{
\item fixed build-time options via \code{judge_args},
\item per-run overrides via \code{judge_call_args} in \code{\link[=adaptive_rank]{adaptive_rank()}},
\item optional per-step overrides via \code{...} passed through
\code{\link[=adaptive_rank_run_live]{adaptive_rank_run_live()}}.
}
Collectively this supports all \code{llm_compare_pair()} options, including
backend-specific parameters such as OpenAI \code{reasoning} and \code{service_tier}.
}
\examples{
judge <- make_adaptive_judge_llm(
  backend = "openai",
  model = "gpt-5.1",
  endpoint = "responses",
  judge_args = list(
    reasoning = "low",
    service_tier = "flex",
    include_thoughts = FALSE
  )
)

}
\seealso{
\code{\link[=adaptive_rank]{adaptive_rank()}}, \code{\link[=adaptive_rank_run_live]{adaptive_rank_run_live()}}, \code{\link[=llm_compare_pair]{llm_compare_pair()}}

Other adaptive ranking: 
\code{\link{adaptive_rank}()},
\code{\link{adaptive_rank_resume}()},
\code{\link{adaptive_rank_run_live}()},
\code{\link{adaptive_rank_start}()},
\code{\link{summarize_adaptive}()}
}
\concept{adaptive ranking}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/openai_live.R
\name{openai_compare_pair_live}
\alias{openai_compare_pair_live}
\title{Live OpenAI comparison for a single pair of samples}
\usage{
openai_compare_pair_live(
  ID1,
  text1,
  ID2,
  text2,
  model,
  trait_name,
  trait_description,
  prompt_template = set_prompt_template(),
  endpoint = c("chat.completions", "responses"),
  tag_prefix = "<BETTER_SAMPLE>",
  tag_suffix = "</BETTER_SAMPLE>",
  api_key = Sys.getenv("OPENAI_API_KEY"),
  ...
)
}
\arguments{
\item{ID1}{Character ID for the first sample.}

\item{text1}{Character string containing the first sample's text.}

\item{ID2}{Character ID for the second sample.}

\item{text2}{Character string containing the second sample's text.}

\item{model}{OpenAI model name (e.g. "gpt-4.1", "gpt-5.1").}

\item{trait_name}{Short label for the trait (e.g., "Overall Quality").}

\item{trait_description}{Full-text definition of the trait.}

\item{prompt_template}{Prompt template string, typically from
\code{\link{set_prompt_template}}.}

\item{endpoint}{Which OpenAI endpoint to use. One of
\code{"chat.completions"} or \code{"responses"}.}

\item{tag_prefix}{Prefix for the better-sample tag. Defaults to
\code{"<BETTER_SAMPLE>"}.}

\item{tag_suffix}{Suffix for the better-sample tag. Defaults to
\code{"</BETTER_SAMPLE>"}.}

\item{api_key}{Optional OpenAI API key. Defaults to
\code{Sys.getenv("OPENAI_API_KEY")}.}

\item{...}{Additional OpenAI parameters, e.g. \code{temperature}, \code{top_p},
\code{logprobs}, \code{reasoning}. The same validation rules for gpt-5.x
models are applied as in \code{\link{build_openai_batch_requests}}.}
}
\value{
A tibble with one row and columns:
\describe{
\item{custom_id}{ID string of the form \code{"LIVE_<ID1>_vs_<ID2>"}.}
\item{ID1, ID2}{The sample IDs you supplied.}
\item{model}{Model name reported by the API.}
\item{object_type}{OpenAI object type (e.g. "chat.completion" or "response").}
\item{status_code}{HTTP-style status code (200 if successful).}
\item{error_message}{Error message if something goes wrong; otherwise NA.}
\item{content}{Raw assistant content string (the LLM output).}
\item{better_sample}{Either "SAMPLE_1", "SAMPLE_2", or NA.}
\item{better_id}{ID1 if SAMPLE_1 chosen, ID2 if SAMPLE_2 chosen, otherwise NA.}
\item{prompt_tokens}{Prompt/input token count (if reported).}
\item{completion_tokens}{Completion/output token count (if reported).}
\item{total_tokens}{Total token count (if reported).}
}
}
\description{
This function sends a single pairwise comparison prompt to the OpenAI API
and parses the result into a small tibble. It is the live/on-demand analogue
of \code{\link{build_openai_batch_requests}} + \code{\link{parse_openai_batch_output}}.
}
\details{
It supports both the Chat Completions endpoint ("/v1/chat/completions") and
the Responses endpoint ("/v1/responses", e.g., for gpt-5.1 with reasoning),
using the same prompt template and model/parameter rules as the batch pipeline.
}
\examples{
\dontrun{
data("example_writing_samples")
td   <- trait_description("overall_quality")
tmpl <- set_prompt_template()

pair <- example_writing_samples[1:2, ]

res <- openai_compare_pair_live(
  ID1               = pair$ID[1],
  text1             = pair$text[1],
  ID2               = pair$ID[2],
  text2             = pair$text[2],
  model             = "gpt-4.1",
  trait_name        = td$name,
  trait_description = td$description,
  prompt_template   = tmpl,
  endpoint          = "chat.completions",
  temperature       = 0
)

res$better_id
}

}

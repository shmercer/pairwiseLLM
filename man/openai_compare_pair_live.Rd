% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/openai_live.R
\name{openai_compare_pair_live}
\alias{openai_compare_pair_live}
\title{Live OpenAI comparison for a single pair of samples}
\usage{
openai_compare_pair_live(
  ID1,
  text1,
  ID2,
  text2,
  model,
  trait_name,
  trait_description,
  prompt_template = set_prompt_template(),
  endpoint = c("chat.completions", "responses"),
  tag_prefix = "<BETTER_SAMPLE>",
  tag_suffix = "</BETTER_SAMPLE>",
  api_key = Sys.getenv("OPENAI_API_KEY"),
  include_raw = FALSE,
  include_thoughts = FALSE,
  ...
)
}
\arguments{
\item{ID1}{Character ID for the first sample.}

\item{text1}{Character string containing the first sample's text.}

\item{ID2}{Character ID for the second sample.}

\item{text2}{Character string containing the second sample's text.}

\item{model}{OpenAI model name (for example "gpt-4.1", "gpt-5.1").}

\item{trait_name}{Short label for the trait (for example "Overall Quality").}

\item{trait_description}{Full-text definition of the trait.}

\item{prompt_template}{Prompt template string, typically from
\code{\link{set_prompt_template}}.}

\item{endpoint}{Which OpenAI endpoint to use. One of
\code{"chat.completions"} or \code{"responses"}.}

\item{tag_prefix}{Prefix for the better-sample tag. Defaults to
\code{"<BETTER_SAMPLE>"}.}

\item{tag_suffix}{Suffix for the better-sample tag. Defaults to
\code{"</BETTER_SAMPLE>"}.}

\item{api_key}{Optional OpenAI API key. Defaults to
\code{Sys.getenv("OPENAI_API_KEY")}.}

\item{include_raw}{Logical; if TRUE, adds a list-column \code{raw_response}
containing the parsed JSON body returned by OpenAI (or NULL on parse
failure). This is useful for debugging parsing problems.}

\item{include_thoughts}{Logical; if TRUE and \code{endpoint = "responses"},
requests a reasoning summary from supported reasoning models by setting
\code{reasoning = list(effort = reasoning, summary = "auto")} and stores
the summary text in a \code{thoughts} column. Defaults to FALSE. For the
Chat Completions endpoint this argument has no effect.}

\item{...}{Additional OpenAI parameters, for example
\code{temperature}, \code{top_p}, \code{logprobs}, \code{reasoning}.
The same validation rules for gpt-5 models are applied as in
\code{\link{build_openai_batch_requests}}.}
}
\value{
A tibble with one row and columns:
\describe{
\item{custom_id}{ID string of the form \code{"LIVE_<ID1>_vs_<ID2>"}.}
\item{ID1, ID2}{The sample IDs you supplied.}
\item{model}{Model name reported by the API.}
\item{object_type}{OpenAI object type (for example "chat.completion" or "response").}
\item{status_code}{HTTP-style status code (200 if successful).}
\item{error_message}{Error message if something goes wrong; otherwise NA.}
\item{thoughts}{Reasoning summary text for reasoning-enabled responses
when \code{include_thoughts = TRUE} and the model returns a summary;
otherwise \code{NA}.}
\item{content}{Concatenated text from the assistant message output (the
LLM's final answer). This is used to locate the \code{<BETTER_SAMPLE>}
tag.}
\item{better_sample}{"SAMPLE_1", "SAMPLE_2", or NA.}
\item{better_id}{ID1 if SAMPLE_1 is chosen, ID2 if SAMPLE_2 is chosen,
otherwise NA.}
\item{prompt_tokens}{Prompt / input token count (if reported).}
\item{completion_tokens}{Completion / output token count (if reported).}
\item{total_tokens}{Total token count (if reported).}
\item{raw_response}{(Optional) list-column containing the parsed JSON body.}
}
}
\description{
This function sends a single pairwise comparison prompt to the OpenAI API
and parses the result into a small tibble. It is the live / on-demand
analogue of \code{\link{build_openai_batch_requests}} plus
\code{\link{parse_openai_batch_output}}.
}
\details{
It supports both the Chat Completions endpoint ("/v1/chat/completions") and
the Responses endpoint ("/v1/responses", for example gpt-5.1 with reasoning),
using the same prompt template and model / parameter rules as the batch
pipeline.

For the Responses endpoint, the function can optionally request and store a
reasoning summary separately from the assistant's final answer:
\itemize{
\item If the API returns a reasoning summary (for example in
\code{body$reasoning$summary} or in an \code{output} item of type
\code{"reasoning"}), that text is stored in a \code{thoughts} column.
\item Assistant message text (the part containing the
\code{<BETTER_SAMPLE>} tag) is stored in \code{content} and used to
determine the preferred sample.
}
}

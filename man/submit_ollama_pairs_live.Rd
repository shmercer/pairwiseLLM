% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ollama_live.R
\name{submit_ollama_pairs_live}
\alias{submit_ollama_pairs_live}
\title{Live Ollama comparisons for a tibble of pairs}
\usage{
submit_ollama_pairs_live(
  pairs,
  model,
  trait_name,
  trait_description,
  prompt_template = set_prompt_template(),
  host = getOption("pairwiseLLM.ollama_host", "http://127.0.0.1:11434"),
  verbose = TRUE,
  status_every = 1,
  progress = TRUE,
  think = FALSE,
  num_ctx = 8192L,
  include_raw = FALSE,
  save_path = NULL,
  parallel = FALSE,
  workers = 1,
  ...
)
}
\arguments{
\item{pairs}{Tibble or data frame with at least columns \code{ID1}, \code{text1},
\code{ID2}, \code{text2}. Typically created by \code{\link[=make_pairs]{make_pairs()}}, \code{\link[=sample_pairs]{sample_pairs()}},
and \code{\link[=randomize_pair_order]{randomize_pair_order()}}.}

\item{model}{Ollama model name (for example \code{"mistral-small3.2:24b"},
\code{"qwen3:32b"}, \code{"gemma3:27b"}).}

\item{trait_name}{Trait name to pass to \code{\link[=ollama_compare_pair_live]{ollama_compare_pair_live()}}.}

\item{trait_description}{Trait description to pass to
\code{\link[=ollama_compare_pair_live]{ollama_compare_pair_live()}}.}

\item{prompt_template}{Prompt template string, typically from
\code{\link[=set_prompt_template]{set_prompt_template()}}.}

\item{host}{Base URL of the Ollama server. Defaults to the option
\code{getOption("pairwiseLLM.ollama_host", "http://127.0.0.1:11434")}.}

\item{verbose}{Logical; if \code{TRUE}, prints status, timing, and result
summaries.}

\item{status_every}{Integer; print status and timing for every
\code{status_every}-th pair. Defaults to 1 (every pair). Errors are always
printed.}

\item{progress}{Logical; if \code{TRUE}, shows a textual progress bar.}

\item{think}{Logical; see \code{\link[=ollama_compare_pair_live]{ollama_compare_pair_live()}} for behavior. When
\code{TRUE} and the model name starts with \code{"qwen"}, the temperature is set
to \code{0.6}; otherwise the temperature remains \code{0}.}

\item{num_ctx}{Integer; context window to use via \code{options$num_ctx}. The
default is \code{8192L}.}

\item{include_raw}{Logical; if \code{TRUE}, each row of the returned tibble will
include a \code{raw_response} list-column with the parsed JSON body from
Ollama. Note: Raw responses are not saved to the incremental CSV file.}

\item{save_path}{Character string; optional file path (e.g., "output.csv")
to save results incrementally. If the file exists, the function reads it
to identify and skip pairs that have already been processed (resume mode).
Requires the \code{readr} package.}

\item{parallel}{Logical; if \code{TRUE}, enables parallel processing using
\code{future.apply}. Requires the \code{future} and \code{future.apply}
packages. Defaults to \code{FALSE}.}

\item{workers}{Integer; the number of parallel workers (threads) to use if
\code{parallel = TRUE}. Defaults to 1.}

\item{...}{Reserved for future extensions and forwarded to
\code{\link[=ollama_compare_pair_live]{ollama_compare_pair_live()}}.}
}
\value{
A list containing three elements:
\describe{
\item{results}{A tibble with one row per successfully processed pair.}
\item{failed_pairs}{A tibble containing the rows from \code{pairs} that
failed to process (due to API errors or timeouts), along with an
\code{error_message} column.}
\item{failed_attempts}{A tibble of attempt-level failures (retries,
timeouts, parse errors, invalid winners), separate from observed outcomes.}
}
}
\description{
\code{submit_ollama_pairs_live()} is a robust row-wise wrapper around
\code{\link[=ollama_compare_pair_live]{ollama_compare_pair_live()}}. It takes a tibble of pairs (\code{ID1} / \code{text1} /
\code{ID2} / \code{text2}), submits each pair to a local (or remote) Ollama server,
and collects the results.
}
\details{
This function offers:
\itemize{
\item \strong{Incremental Saving:} Writes results to a CSV file as they complete.
If the process is interrupted, re-running the function with the same
\code{save_path} will automatically skip pairs that were already successfully processed.
\item \strong{Parallel Processing:} Uses the \code{future} package to process
multiple pairs simultaneously. \strong{Note:} Since Ollama typically runs
locally on the GPU, parallel processing may degrade performance or cause
out-of-memory errors unless the hardware can handle concurrent requests.
Defaults are set to sequential processing.
}

Temperature and context length are controlled as follows:
\itemize{
\item By default, \code{temperature = 0} for all models.
\item For Qwen models (model names beginning with \code{"qwen"}) and \code{think = TRUE},
\code{temperature} is set to \code{0.6}.
\item The context window is set via \code{options$num_ctx}, which defaults to
\code{8192} but may be overridden via the \code{num_ctx} argument.
}

In most user-facing workflows, it is more convenient to call
\code{\link[=submit_llm_pairs]{submit_llm_pairs()}} with \code{backend = "ollama"} rather than using
\code{submit_ollama_pairs_live()} directly.

As with \code{\link[=ollama_compare_pair_live]{ollama_compare_pair_live()}}, this function assumes that:
\itemize{
\item An Ollama server is running and reachable at \code{host}.
\item The requested models have been pulled in advance (for example
\verb{ollama pull mistral-small3.2:24b}).
}
}
\examples{
\dontrun{
# Requires a running Ollama server and locally available models.

data("example_writing_samples", package = "pairwiseLLM")

pairs <- example_writing_samples |>
  make_pairs() |>
  sample_pairs(n_pairs = 5, seed = 123) |>
  randomize_pair_order(seed = 456)

td <- trait_description("overall_quality")
tmpl <- set_prompt_template()

# Live comparisons with incremental saving
res_mistral <- submit_ollama_pairs_live(
  pairs             = pairs,
  model             = "mistral-small3.2:24b",
  trait_name        = td$name,
  trait_description = td$description,
  prompt_template   = tmpl,
  save_path         = "ollama_results.csv",
  verbose           = TRUE
)

# Access results
res_mistral$results
}

}
\seealso{
\itemize{
\item \code{\link[=ollama_compare_pair_live]{ollama_compare_pair_live()}} for single-pair Ollama comparisons.
\item \code{\link[=submit_llm_pairs]{submit_llm_pairs()}} for backend-agnostic comparisons over tibbles of
pairs.
}
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bt_run_core_linking.R
\name{bt_run_core_linking}
\alias{bt_run_core_linking}
\title{Run a core-linking batch workflow end-to-end (round-based)}
\usage{
bt_run_core_linking(
  samples,
  batches,
  core_ids = NULL,
  core_method = c("auto", "pam", "clara", "embeddings", "token_stratified", "random"),
  core_size = 30,
  embeddings = NULL,
  linking = c("auto", "always", "never"),
  linking_method = c("median_iqr", "median_mad", "mean_sd"),
  linking_cor_target = 0.98,
  linking_p90_abs_shift_target = 0.15,
  linking_max_abs_shift_target = 0.3,
  linking_min_n = 3L,
  reference_scale_method = c("median_iqr", "median_mad", "mean_sd"),
  reference_max_abs = 6,
  judge_fun,
  initial_results = NULL,
  judge = NULL,
  fit_fun = fit_bt_model,
  build_bt_fun = build_bt_data,
  engine = "sirt",
  fit_verbose = FALSE,
  return_diagnostics = TRUE,
  include_residuals = FALSE,
  fit_engine_running = c("bt", "rank_centrality"),
  store_running_estimates = TRUE,
  rc_smoothing = 0.5,
  rc_damping = 0,
  final_refit = TRUE,
  final_bt_bias_reduction = TRUE,
  round_size = 50,
  max_rounds_per_batch = 50,
  within_batch_frac = 0.25,
  core_audit_frac = 0.1,
  allocation = c("fixed", "precision_ramp", "audit_on_drift"),
  allocation_fun = NULL,
  k_neighbors = 10,
  min_judgments = 12,
  forbid_repeats = TRUE,
  balance_positions = TRUE,
  se_probs = c(0.5, 0.9, 0.95),
  fit_bounds = c(0.7, 1.3),
  stopping_tier = c("strong", "good", "very_strong"),
  reliability_target = 0.9,
  sepG_target = 3,
  rel_se_p90_target = 0.3,
  rel_se_p90_min_improve = 0.01,
  max_item_misfit_prop = 0.05,
  max_judge_misfit_prop = 0.05,
  core_theta_cor_target = NA_real_,
  core_theta_spearman_target = NA_real_,
  core_max_abs_shift_target = NA_real_,
  core_p90_abs_shift_target = NA_real_,
  drift_reference = c("previous_round", "baseline"),
  seed = NULL,
  verbose = TRUE,
  checkpoint_dir = NULL,
  resume_from = NULL,
  checkpoint_every = 1L,
  checkpoint_store_fits = TRUE,
  checkpoint_overwrite = TRUE,
  ...
)
}
\arguments{
\item{samples}{A tibble/data.frame with columns \code{ID} and \code{text}. \code{ID}
must be unique and non-missing.}

\item{batches}{A non-empty list where each element is a character vector of IDs to
be added in that batch. IDs must be present in \code{samples$ID}.}

\item{core_ids}{Optional character vector of core IDs. If \code{NULL}, core IDs are
selected using \code{\link{select_core_set}}.}

\item{core_method}{Core selection method used when \code{core_ids} is \code{NULL}.
Passed to \code{\link{select_core_set}}.}

\item{core_size}{Core size used when \code{core_ids} is \code{NULL}.}

\item{embeddings}{Optional embedding matrix for embeddings-based core selection
(\code{core_method} in \code{c("auto","pam","clara","embeddings")}).}

\item{linking}{Whether to apply anchoring/linking so theta estimates are reported
on a stable scale defined by the baseline core fit. One of
\code{"auto"}, \code{"always"}, or \code{"never"}. In \code{"auto"},
linking is applied only when core drift exceeds the thresholds below.}

\item{linking_method}{Linking method passed to \code{\link[=bt_link_thetas]{bt_link_thetas()}}.
Robust methods (\code{"median_iqr"}, \code{"median_mad"}) are recommended when
rounds are close to deterministic (separation).}

\item{linking_cor_target}{In \code{linking = "auto"}, apply linking when the core
Pearson correlation between baseline and current raw thetas is below this value.}

\item{linking_p90_abs_shift_target}{In \code{linking = "auto"}, apply linking when the
90th percentile of the absolute core-theta shift (baseline vs current raw) exceeds
this value.}

\item{linking_max_abs_shift_target}{In \code{linking = "auto"}, apply linking when the
maximum absolute core-theta shift (baseline vs current raw) exceeds this value.}

\item{linking_min_n}{Minimum number of core IDs required to estimate the linking
transform. If fewer are available, linking is skipped.}

\item{reference_scale_method}{Method used to stabilize the \emph{reference} (baseline)
theta scale before it is used for linking decisions. Defaults to a robust
median/IQR-based scale. This reduces pathological behavior when the early core
fit is close to deterministic (separation).}

\item{reference_max_abs}{Maximum absolute value allowed for reference thetas after
stabilization (clamping). This is applied only to the reference fit used for
linking/drift diagnostics.}

\item{judge_fun}{Function that accepts a tibble of pairs with columns \code{ID1},
\code{text1}, \code{ID2}, \code{text2} and returns a tibble with columns
\code{ID1}, \code{ID2}, \code{better_id}. If \code{judge} is provided, the output
must also include that column.}

\item{initial_results}{Optional tibble of previously-judged results (same schema as
output of \code{judge_fun}). Used as a warm start.}

\item{judge}{Optional string naming the judge column to pass through to modeling.}

\item{fit_fun}{Function that fits a BT model from BT data (default \code{\link{fit_bt_model}}).}

\item{build_bt_fun}{Function to build BT data from results (default \code{\link{build_bt_data}}).}

\item{engine}{Passed to \code{fit_fun} when \code{fit_fun = fit_bt_model}.}

\item{fit_verbose}{Passed to \code{fit_fun} when \code{fit_fun = fit_bt_model}.}

\item{return_diagnostics}{Passed to \code{fit_fun} when \code{fit_fun = fit_bt_model}.}

\item{include_residuals}{Passed to \code{fit_fun} when \code{fit_fun = fit_bt_model}.}

\item{fit_engine_running}{Running fitting engine used to propose the \emph{next} round
of pairs. One of \code{"bt"} (default; uses the linked BT thetas when available)
or \code{"rank_centrality"} (Rank Centrality via \code{\link{fit_rank_centrality}}).}

\item{store_running_estimates}{Logical; if TRUE (default) store the per-round
\emph{running} fits in \code{$fits}. When FALSE, store the raw BT fits.}

\item{rc_smoothing, rc_damping}{Passed to \code{\link{fit_rank_centrality}} when
\code{fit_engine_running = "rank_centrality"}.}

\item{final_refit}{Logical; if TRUE (default), compute a final combined estimates
table via \code{\link{compute_final_estimates}} on all accumulated results.}

\item{final_bt_bias_reduction}{Logical; if TRUE (default), attempt bias-reduced
Bradley--Terry (Firth) at the final refit when \code{final_refit = TRUE}.}

\item{round_size}{Target number of pairs proposed per round (per batch).}

\item{max_rounds_per_batch}{Maximum rounds to run for each batch.}

\item{within_batch_frac}{Fraction of each round allocated to new<->new comparisons.}

\item{core_audit_frac}{Fraction of each round allocated to core<->core audit comparisons.}

\item{allocation}{Allocation preset controlling how within-batch and auditing
fractions may be adjusted between rounds. One of \code{"fixed"}, \code{"precision_ramp"},
or \code{"audit_on_drift"}. If \code{allocation_fun} is supplied, it takes precedence
and \code{allocation} is ignored.}

\item{allocation_fun}{Optional function to update \code{within_batch_frac} and/or \code{core_audit_frac}
between rounds. It is called after metrics are computed each round with a state list containing
(at minimum) \code{batch_index}, \code{round_index}, \code{within_batch_frac}, \code{core_audit_frac}, \code{metrics},
and \code{prev_metrics}. It should return NULL (no change) or a list with elements
\code{within_batch_frac} and/or \code{core_audit_frac}.}

\item{k_neighbors}{Passed to \code{\link{select_core_link_pairs}}.}

\item{min_judgments}{Passed to \code{\link{select_core_link_pairs}}.}

\item{forbid_repeats}{Forbid repeat unordered pairs across the entire run.}

\item{balance_positions}{Balance positions (ID1 vs ID2) when proposing pairs.}

\item{se_probs}{Passed to \code{\link{bt_stop_metrics}}.}

\item{fit_bounds}{Passed to \code{\link{bt_stop_metrics}} when diagnostics are available.}

\item{stopping_tier}{Preset stopping thresholds to use (good/strong/very_strong).}

\item{reliability_target}{Passed to \code{\link{bt_should_stop}}.}

\item{sepG_target}{Passed to \code{\link{bt_should_stop}}.}

\item{rel_se_p90_target}{Passed to \code{\link{bt_should_stop}}.}

\item{rel_se_p90_min_improve}{Passed to \code{\link{bt_should_stop}}.}

\item{max_item_misfit_prop}{Passed to \code{\link{bt_should_stop}}.}

\item{max_judge_misfit_prop}{Passed to \code{\link{bt_should_stop}}.}

\item{core_theta_cor_target}{Optional drift guardrail for Pearson correlation
(default \code{NA} = disabled).}

\item{core_theta_spearman_target}{Optional drift guardrail for Spearman correlation
(default \code{NA} = disabled).}

\item{core_max_abs_shift_target}{Optional drift guardrail for maximum abs shift
(default \code{NA} = disabled).}

\item{core_p90_abs_shift_target}{Optional drift guardrail for p90 abs shift
(default \code{NA} = disabled).}

\item{drift_reference}{Drift reference for computing core drift metrics:
\code{"previous_round"} compares to the prior round's fit; \code{"baseline"} compares
to a fixed baseline fit.}

\item{seed}{Optional integer seed used to make pair proposal reproducible across runs.}

\item{verbose}{Logical; print minimal progress per batch/round.}

\item{checkpoint_dir}{Optional directory path for writing checkpoint files during
the run. If provided, the runner writes \code{run_state.rds} (and optionally
per-round snapshot files) after completed rounds and/or batch boundaries. Use
this to resume long jobs after interruption or errors.}

\item{resume_from}{Optional directory path containing a prior checkpoint file
\code{run_state.rds} created by \code{bt_run_core_linking()}. When provided, the
run resumes from the saved state, including accumulated results and batch/round
indices. The \code{samples}, \code{batches}, and \code{core_ids} must be
compatible with the checkpoint.}

\item{checkpoint_every}{Integer controlling how frequently per-round snapshot
files are written. A value of \code{1} writes a snapshot after every completed
round; a value of \code{2} writes snapshots every other round, etc. The main
file \code{run_state.rds} is still updated at safe points even when
\code{checkpoint_every > 1}.}

\item{checkpoint_store_fits}{Logical indicating whether to store fitted model
objects (BT fits and diagnostics) inside checkpoint files. Set to \code{FALSE}
to reduce checkpoint size; fits may be recomputed after resuming.}

\item{checkpoint_overwrite}{Logical indicating whether to overwrite an existing
\code{run_state.rds} file in \code{checkpoint_dir}. If \code{FALSE} and a
checkpoint already exists, the function should error rather than overwrite.}

\item{...}{Additional arguments forwarded to \code{fit_fun}.}
}
\value{
A list with:
\describe{
\item{core_ids}{Core linking IDs used.}
\item{batches}{Normalized batches list.}
\item{results}{All judged results (canonicalized \code{better_id}).}
\item{fits}{List of per-round fits (including bootstrap/warm start).}
\item{final_fits}{Named list of final fit per batch (plus \code{"bootstrap"}).}
\item{metrics}{Tibble of stop metrics per round (computed on batch new IDs).}
\item{state}{A tibble with one row per scoring round (including bootstrap/warm start)
containing bookkeeping summaries of the accumulated results (overall and for the
current batch's new IDs). The overall fields include
\code{n_unique_unordered_pairs}, appearance quantiles, \code{pos_imbalance_max},
\code{n_self_pairs}, \code{n_missing_better_id}, and \code{n_judges} (if applicable).
New-ID-restricted fields are prefixed with \code{new_}. Rows also include
\code{batch_index}, \code{round_index}, \code{stage}, and (when applicable)
\code{stop_reason}.}
\item{batch_summary}{One row per batch: rounds used, stop reason, counts.}
}
}
\description{
This runner orchestrates a multi-wave (batch) workflow using a stable core
linking set. For each batch of new items, it runs a round-based loop:
propose pairs (core↔new + new↔new + optional core↔core audit), score the pairs
via \code{judge_fun}, append results, fit a BT model, compute stop metrics on
the batch's new IDs (optionally including core drift), then stop or continue.
}
\details{
Stopping is typically driven by precision on the batch's new items (e.g.,
\code{rel_se_p90}) and can be gated by core drift guardrails
(via \code{core_*_target} thresholds).

The runner also records a compact per-round \emph{state snapshot} that summarizes
the accumulated judged results after each round. These summaries are returned in
\code{$state} and include both overall counts (all IDs) and \code{new_}-prefixed
counts restricted to the current batch's new IDs.

\strong{Checkpointing and resuming:} If \code{checkpoint_dir} is provided, this
function writes a checkpoint representing the last completed safe point (after a
round completes, and at batch boundaries). If the run is interrupted, resume by
calling again with \code{resume_from = checkpoint_dir}.
}
\examples{
# CRAN-safe example (no APIs, no sirt): deterministic simulated judging + mock fit.
samples <- tibble::tibble(
  ID = LETTERS[1:6],
  text = paste("text", LETTERS[1:6])
)
batches <- list(batch1 = c("D", "E"), batch2 = c("F"))
core_ids <- c("A", "B", "C")

# Deterministic simulated judge (always picks the higher true theta)
true_theta <- c(A = 2, B = 1, C = 0, D = -1, E = -2, F = -3)
judge_fun <- function(pairs) simulate_bt_judge(pairs, true_theta, deterministic = TRUE)

# Tiny mock fit: returns required structure (ID/theta/se)
round <- 0
mock_fit <- function(bt_data, ...) {
  round <<- round + 1
  ids <- sort(unique(c(bt_data$object1, bt_data$object2)))
  se <- rep(max(0.60 - 0.15 * round, 0.05), length(ids))
  list(
    engine = "mock",
    reliability = NA_real_,
    theta = tibble::tibble(ID = ids, theta = seq_along(ids), se = se),
    diagnostics = list(sepG = NA_real_)
  )
}

out <- bt_run_core_linking(
  samples = samples,
  batches = batches,
  core_ids = core_ids,
  judge_fun = judge_fun,
  fit_fun = mock_fit,
  engine = "mock",
  round_size = 8,
  max_rounds_per_batch = 3,
  # disable thresholds requiring sirt diagnostics for this example
  reliability_target = NA_real_,
  sepG_target = NA_real_,
  max_item_misfit_prop = NA_real_,
  max_judge_misfit_prop = NA_real_,
  rel_se_p90_target = 0.80,
  verbose = FALSE
)
out$batch_summary

}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/adaptive_run.R
\name{adaptive_rank_run_batch}
\alias{adaptive_rank_run_batch}
\title{Run adaptive ranking in a batch loop}
\usage{
adaptive_rank_run_batch(
  samples,
  model,
  trait_name,
  trait_description,
  prompt_template = NULL,
  backend = NULL,
  submission = list(),
  adaptive = list(),
  paths = list(state_path = NULL, output_dir = NULL),
  seed = NULL,
  max_iterations = NULL
)
}
\arguments{
\item{samples}{A data frame or tibble with columns \code{ID} and \code{text}.}

\item{model}{Model identifier for the selected backend.}

\item{trait_name}{Short label for the trait.}

\item{trait_description}{Full-text trait description.}

\item{prompt_template}{Optional prompt template string. Defaults to
\code{set_prompt_template()}.}

\item{backend}{Backend name (batch-capable): one of \code{"openai"},
\code{"anthropic"}, \code{"gemini"}, \code{"together"}, or \code{"ollama"}.
(Note: actual batch support depends on the backend implementation.)}

\item{submission}{A list of arguments passed through to
\code{llm_submit_pairs_multi_batch()} (and the corresponding resume/polling
functions) on each batch submission. This wrapper will force
\code{submission$n_segments <- 1}. During polling, the wrapper will filter
the list to the formals of \code{llm_resume_multi_batches()} before calling
\code{adaptive_rank_resume()}.}

\item{adaptive}{A list of adaptive configuration overrides. See
\code{adaptive_rank_start()} for supported keys.}

\item{paths}{A list with optional \code{state_path} and \code{output_dir}.
Batch mode strongly benefits from setting these so the run can be resumed.}

\item{seed}{Optional integer seed for deterministic scheduling.}

\item{max_iterations}{Optional override for the batch loop cap. Use \code{Inf}
(or \code{adaptive$max_iterations = NULL}) for no cap.}
}
\value{
A list with:
\describe{
\item{state}{The final \code{adaptive_state}.}
\item{submission_info}{Metadata for the last submission.}
\item{next_action}{List with \code{action} and \code{reason}.}
\item{iterations}{Number of iterations executed.}
}
}
\description{
Convenience wrapper that repeatedly calls
\code{adaptive_rank_start()} and \code{adaptive_rank_resume()} in batch mode
until the budget is exhausted, no feasible pairs remain, or
\code{max_iterations} is reached.
}
\details{
This wrapper is intended for hosted backends that support batch submission
(e.g., Gemini). It forces \code{n_segments = 1} so each adaptive iteration
submits a single batch segment (rather than splitting into multiple segments).

Running this function will submit LLM comparisons and will incur API usage
costs for hosted backends. Batch mode is recommended for longer runs because
it supports checkpointing and controlled polling behavior. When
\code{paths$state_path} points to an existing checkpoint, the wrapper resumes that
run (with strict sample validation) instead of starting fresh.

Some backends and helper functions accept different arguments for batch
submission vs polling/resume. This wrapper uses \code{formals()}-based
filtering to pass only arguments that are accepted by the polling function
(currently \code{llm_resume_multi_batches()}) during the resume loop. This
prevents unused-argument errors when the same \code{submission} list contains
submit-only keys (e.g., \code{n_segments}, \code{progress}).
}
\examples{
\dontrun{
# Gemini batch loop, single segment per iteration
out <- adaptive_rank_run_batch(
  samples = samples,
  model = "gemini-3-flash-preview",
  trait_name = td$name,
  trait_description = td$description,
  backend = "gemini",
  submission = list(
    # submit-time and poll-time controls may be mixed here;
    # submit-only keys will be filtered out automatically during polling
    interval_seconds = 60,
    per_job_delay = 2,
    progress = TRUE,
    verbose = TRUE
  ),
  paths = list(
    state_path = "./dev-output/adaptive_gemini/state.rds",
    output_dir = "./dev-output/adaptive_gemini"
  ),
  seed = 123,
  max_iterations = 10
)
}

}

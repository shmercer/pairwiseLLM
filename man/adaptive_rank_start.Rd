% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/adaptive_run.R
\name{adaptive_rank_start}
\alias{adaptive_rank_start}
\title{Adaptive pairwise ranking with warm start and Bayesian refinement}
\usage{
adaptive_rank_start(
  samples,
  model,
  trait_name,
  trait_description,
  prompt_template = NULL,
  backend = NULL,
  mode = c("live", "batch"),
  submission = list(),
  adaptive = list(),
  paths = list(state_path = NULL, output_dir = NULL),
  seed = NULL
)
}
\arguments{
\item{samples}{A data frame or tibble with columns \code{ID} and \code{text}.}

\item{model}{Model identifier for the selected backend.}

\item{trait_name}{Short label for the trait.}

\item{trait_description}{Full-text trait description.}

\item{prompt_template}{Optional prompt template string. Defaults to
\code{set_prompt_template()}.}

\item{backend}{Backend name. For live mode: one of \code{"openai"},
\code{"anthropic"}, \code{"gemini"}, \code{"together"}, or \code{"ollama"}.
For batch mode: one of \code{"openai"}, \code{"anthropic"}, or
\code{"gemini"}.}

\item{mode}{Submission mode. Either \code{"live"} or \code{"batch"}.}

\item{submission}{A list of arguments passed through to
\code{submit_llm_pairs()} (live) or \code{llm_submit_pairs_multi_batch()}
(batch). Common options include \code{endpoint}, \code{include_raw},
\code{batch_size}, and \code{n_segments}. The list is extensible in future
versions.}

\item{adaptive}{A list of adaptive configuration overrides. Supported keys
include: \code{d1} (default 8), \code{bins} (8), \code{mix_struct} (0.70),
\code{within_adj_split} (0.50), \code{exploration_frac} (0.05),
\code{per_item_cap} (NULL), \code{batch_overrides} (list),
\code{max_refill_rounds} (2),
\code{max_replacements} (NULL), \code{max_iterations} (50),
\code{budget_max} (NULL; defaults to 0.40 * choose(N,2)), and
\code{M1_target} (NULL; defaults to floor(N * d1 / 2)). The list is
extensible in future versions. Use \code{adaptive$v3} to override v3
config fields such as \code{progress}, \code{progress_every_iter},
\code{progress_every_refit}, and \code{progress_level}.}

\item{paths}{A list with optional \code{state_path} and \code{output_dir}.
For batch mode, \code{state_path} defaults to
\code{file.path(output_dir, "adaptive_state.rds")}.}

\item{seed}{Optional integer seed for deterministic scheduling.}
}
\value{
A list with:
\describe{
\item{state}{The updated \code{adaptive_state}.}
\item{state_path}{Path where the state was saved (batch mode only).}
\item{submission_info}{Metadata needed for resume, including pairs submitted.}
\item{next_action}{List with \code{action} and \code{reason}.}
}
}
\description{
Initialize an adaptive ranking run, schedule Phase 1 warm-start pairs, and
submit them in live or batch mode. Live mode submits immediately and ingests
observed outcomes. Batch mode submits jobs, saves state, and returns resume
metadata for later polling. A single call may not complete the full run;
use \code{adaptive_rank_resume()} to continue.
}
\details{
Adaptive ranking proceeds in three phases: Phase 1 (warm start), Phase 2
(adaptive refinement), and Phase 3 (near-stop polish). \code{adaptive_rank_start()}
creates a fresh \code{adaptive_state}, schedules Phase 1 pairs up to the
Phase 1 target, and submits those comparisons. \code{adaptive_rank_resume()}
ingests newly observed results and schedules subsequent adaptive batches.

Exposure and observation are distinct. Scheduled comparisons update exposure
counters immediately (pairs, degrees, position counts), while observed
outcomes are ingested only after a backend returns results. Failed attempts
are logged separately and never treated as observations. This separation
prevents retries or missing results from contaminating the ranking signal.

The adaptive engine uses a confirmation window (CW) based on observed
comparisons, along with a two-check confirmation rule, to decide when to
stop refinement. Fast inference provides selection-grade posterior draws for
adaptive selection and stopping checks. Final uncertainty summaries are
produced only after the full MCMC audit.

All LLM outputs are normalized into a single canonical results schema,
independent of backend, and all downstream logic operates exclusively on
this canonical form.

Canonical adaptive outputs are \code{batch_log}, \code{round_log}, and
\code{item_summary}. The logs live on the state as \code{state$batch_log} and
\code{state$config$round_log}. When outputs are written, the final
\code{item_summary} is cached on \code{state$config$item_summary}; summary
helpers are pure views of these tables.
}
\examples{
# Minimal synthetic setup (no submission).
samples <- tibble::tibble(
  ID = c("S1", "S2", "S3", "S4"),
  text = c("alpha", "bravo", "charlie", "delta")
)
td <- trait_description("overall_quality")
adaptive_cfg <- list(d1 = 8, M1_target = 40)

\dontrun{
# Live start (submits immediately and ingests observed results)
start_out <- adaptive_rank_start(
  samples = samples,
  model = "gpt-4.1",
  trait_name = td$name,
  trait_description = td$description,
  backend = "openai",
  mode = "live",
  adaptive = adaptive_cfg,
  seed = 123
)

# Live resume (continues scheduling; may require multiple calls)
resume_out <- adaptive_rank_resume(
  state = start_out$state,
  mode = "live",
  submission_info = start_out$submission_info,
  adaptive = adaptive_cfg,
  seed = 123
)

# Batch start (submits jobs and returns resume info)
batch_out <- adaptive_rank_start(
  samples = samples,
  model = "gpt-4.1",
  trait_name = td$name,
  trait_description = td$description,
  backend = "openai",
  mode = "batch",
  submission = list(batch_size = 1000, write_registry = TRUE),
  paths = list(output_dir = "adaptive_runs"),
  adaptive = adaptive_cfg,
  seed = 123
)

# Batch resume loop (poll until done)
next_action <- batch_out$next_action
state <- batch_out$state
submission_info <- batch_out$submission_info
while (identical(next_action$action, "resume")) {
  res <- adaptive_rank_resume(
    state = state,
    mode = "batch",
    submission_info = submission_info,
    adaptive = adaptive_cfg,
    seed = 123
  )
  state <- res$state
  submission_info <- res$submission_info
  next_action <- res$next_action
}
}

}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/adaptive_run.R
\name{adaptive_rank_start}
\alias{adaptive_rank_start}
\title{Adaptive pairwise ranking with warm start and Bayesian refinement}
\usage{
adaptive_rank_start(
  samples,
  model,
  trait_name,
  trait_description,
  prompt_template = NULL,
  backend = NULL,
  mode = c("live", "batch"),
  submission = list(),
  adaptive = list(),
  paths = list(state_path = NULL, output_dir = NULL),
  seed = NULL
)
}
\arguments{
\item{samples}{A data frame or tibble with columns \code{ID} and \code{text}.}

\item{model}{Model identifier for the selected backend.}

\item{trait_name}{Short label for the trait.}

\item{trait_description}{Full-text trait description.}

\item{prompt_template}{Optional prompt template string. Defaults to
\code{set_prompt_template()}.}

\item{backend}{Backend name. For live mode: one of \code{"openai"},
\code{"anthropic"}, \code{"gemini"}, \code{"together"}, or \code{"ollama"}.
For batch mode: one of \code{"openai"}, \code{"anthropic"}, or
\code{"gemini"}.}

\item{mode}{Submission mode. Either \code{"live"} or \code{"batch"}.}

\item{submission}{A list of arguments passed through to
\code{submit_llm_pairs()} (live) or \code{llm_submit_pairs_multi_batch()}
(batch). Common options include \code{endpoint}, \code{include_raw},
\code{batch_size}, and \code{n_segments}. The list is extensible in future
versions.}

\item{adaptive}{A list of adaptive configuration overrides. See the
"Adaptive configuration" and "Canonical outputs" sections for v3-specific
controls, stopping thresholds, and logging behavior. Progress printing is
enabled by default; set \code{adaptive$v3$progress = FALSE} for silent
runs or adjust \code{progress_level} for more detail.}

\item{paths}{A list with optional \code{state_path} and \code{output_dir}.
For batch mode, \code{state_path} defaults to
\code{file.path(output_dir, "adaptive_state.rds")}.}

\item{seed}{Optional integer seed for deterministic scheduling.}
}
\value{
A list with:
\describe{
\item{state}{The updated \code{adaptive_state}.}
\item{state_path}{Path where the state was saved (batch mode only).}
\item{submission_info}{Metadata needed for resume, including pairs submitted.}
\item{next_action}{List with \code{action} and \code{reason}.}
\item{final_summary}{Cached summary payload, if produced.}
}
}
\description{
Initialize an adaptive ranking run, schedule Phase 1 warm-start pairs, and
submit them in live or batch mode. Live mode submits immediately and ingests
observed outcomes. Batch mode submits jobs, saves state, and returns resume
metadata for later polling. A single call may not complete the full run;
use \code{adaptive_rank_resume()} to continue.
}
\details{
Adaptive ranking proceeds in three phases: Phase 1 (warm start), Phase 2
(adaptive refinement), and Phase 3 (near-stop polish). Phase 3 entry is
evaluated only after a refit in Phase 2: diagnostics must pass and
\code{reliability_EAP >= max(0, eap_reliability_min - 0.05)}. Phase transitions
are one-way (\code{phase2 -> phase3} only). \code{adaptive_rank_start()}
creates a fresh \code{adaptive_state}, schedules Phase 1 pairs up to the
Phase 1 target, and submits those comparisons. \code{adaptive_rank_resume()}
ingests newly observed results and schedules subsequent adaptive batches.

Exposure and observation are distinct. Scheduled comparisons update exposure
counters immediately (pairs, degrees, position counts), while observed
outcomes are ingested only after a backend returns results. Failed attempts
are logged separately and never treated as observations. This separation
prevents retries or missing results from contaminating the ranking signal.

Adaptive refits are triggered when at least \code{refit_B} new observations
arrive since the last refit (or when the first refit is needed). Each refit
updates the posterior used for scheduling and stopping checks. When stopping
criteria are met, the state moves to \code{mode = "stopped"} and no new
batches are scheduled.

All LLM outputs are normalized into a single canonical results schema,
independent of backend, and all downstream logic operates exclusively on
this canonical form.
}
\section{Model variants}{

Adaptive v3 tracks model variants in the fit contract and logs. Supported
labels include \code{"btl"} (plain Bradley--Terry), \code{"btl_e"} (lapse
epsilon), \code{"btl_b"} (position bias beta), and \code{"btl_e_b"} (both;
default). Variants that omit parameters still carry the full output schema:
percentile columns such as \code{epsilon_p2.5} or \code{beta_p50} remain
present and are \code{NA} when the parameter is not estimated.
}

\section{Stopping logic}{

Stopping is a staged gate evaluated only after a refit. First, the run must
meet the minimum observed comparisons (\code{M1_target}). Next, diagnostics
must pass: zero divergences, \code{max_rhat} below \code{max_rhat}, and
\code{min_ess_bulk} above a threshold (using \code{min_ess_bulk_near_stop}
once near-stop checks begin). Diagnostics status is recorded as
\code{diagnostics_pass}. If diagnostics pass, reliability must exceed
\code{eap_reliability_min}; \code{eap_pass} is TRUE when
\code{reliability_EAP} meets the threshold and \code{diagnostics_pass} is
TRUE, and otherwise is \code{NA}. Stability is evaluated against a lagged
refit when \code{lag_eligible} is TRUE (current refit exceeds
\code{stability_lag}). Lagged metrics \code{rho_theta_lag} (Pearson),
\code{delta_sd_theta_lag}, and \code{rho_rank_lag} (Spearman) are \code{NA}
when lag-ineligible; the corresponding pass flags
(\code{theta_corr_pass}, \code{delta_sd_theta_pass}, \code{rho_rank_pass})
are also \code{NA} and treated as satisfied until lag eligibility. A stop is
declared immediately when all gates pass at an eligible refit (no consecutive
passes are required).
}

\section{Adaptive configuration}{

The \code{adaptive} list controls run-scale scheduling:
\describe{
\item{\code{d1}}{Warm-start degree target used to compute the default
\code{M1_target} (\code{floor(N * d1 / 2)}).}
\item{\code{bins}}{Reserved for legacy binning logic; currently unused.}
\item{\code{mix_struct}}{Reserved for legacy mixing logic; currently unused.}
\item{\code{within_adj_split}}{Reserved for legacy adjacency splits;
currently unused.}
\item{\code{exploration_frac}}{Reserved for legacy exploration logic;
currently unused in v3 scheduling.}
\item{\code{per_item_cap}}{Reserved per-item cap; currently unused.}
\item{\code{batch_overrides}}{Named list overriding batch sizes computed by
\code{compute_batch_sizes()} (e.g., \code{BATCH1}, \code{BATCH2},
\code{BATCH3}, \code{CW}).}
\item{\code{max_refill_rounds}}{Maximum number of live replacement rounds
attempted when submissions are missing.}
\item{\code{max_replacements}}{Maximum number of replacement pairs per
iteration; defaults to the batch size.}
\item{\code{max_iterations}}{Maximum number of start/resume iterations in
wrappers such as \code{adaptive_rank_run_live()} (NULL means no cap).}
\item{\code{budget_max}}{Hard cap on scheduled comparisons; defaults to
\code{floor(0.40 * choose(N, 2))}.}
\item{\code{M1_target}}{Minimum observed comparisons before stop checks
are eligible; defaults to \code{floor(N * d1 / 2)}.}
}
The \code{adaptive$v3} list overrides v3 configuration fields:
\describe{
\item{\code{W}}{Window size used in candidate generation.}
\item{\code{A_anchors}}{Anchor count used in candidate selection.}
\item{\code{C_max}}{Maximum candidate pairs considered per stage.}
\item{\code{refit_B}}{Refit cadence in newly observed pairs.}
\item{\code{batch_size}}{Target pairs scheduled per iteration.}
\item{\code{explore_rate}}{Fraction of exploration pairs within a batch.}
\item{\code{min_degree}}{Warm-start minimum degree per item.}
\item{\code{target_mean_degree}}{Optional warm-start mean degree target;
expands the initial schedule when set.}
\item{\code{dup_p_margin}}{Repeat allowance margin for ambiguous pairs.}
\item{\code{dup_max_count}}{Maximum repeated presentations per unordered
pair.}
\item{\code{dup_utility_quantile}}{Utility quantile for repeat allowance.}
\item{\code{hard_cap_frac}}{Fraction of all unordered pairs that triggers
the hard stop (\code{0.40} by default).}
\item{\code{eap_reliability_min}}{Minimum \code{reliability_EAP} for stop
eligibility.}
\item{\code{stability_lag}}{Lag (in refits) used to compare theta and rank
stability.}
\item{\code{theta_corr_min}}{Minimum correlation between current and lagged
theta means.}
\item{\code{theta_sd_rel_change_max}}{Maximum relative change in theta SD
versus the lagged refit.}
\item{\code{rank_spearman_min}}{Minimum Spearman correlation between
current and lagged ranks.}
\item{\code{max_rhat}}{Maximum allowed R-hat for diagnostics pass.}
\item{\code{min_ess_bulk}}{Minimum bulk ESS for diagnostics pass.}
\item{\code{min_ess_bulk_near_stop}}{Minimum bulk ESS once near-stop checks
have begun.}
\item{\code{require_divergences_zero}}{Reserved; diagnostics currently
require zero divergences regardless of this value.}
\item{\code{repair_max_cycles}}{Maximum repair cycles before giving up.}
\item{\code{progress}}{Logical toggle for progress reporting.}
\item{\code{progress_every_iter}}{Iteration cadence for progress prints.}
\item{\code{progress_every_refit}}{Refit cadence for progress prints.}
\item{\code{progress_level}}{Verbosity level: \code{"basic"},
\code{"refit"}, or \code{"full"}.}
\item{\code{write_outputs}}{Whether to write \code{batch_log} and
\code{round_log} to disk; item logs are written per refit.}
\item{\code{output_dir}}{Directory used for adaptive artifacts when
\code{write_outputs = TRUE}.}
\item{\code{keep_draws}}{Whether to write thinned posterior draws to disk.}
\item{\code{thin_draws}}{Thinning interval for saved draws.}
\item{\code{cmdstan}}{CmdStan configuration list (chains, parallelism,
core fraction, output directory).}
}
}

\section{Canonical outputs}{

Canonical adaptive outputs are \code{batch_log}, \code{round_log}, and
\code{item_log_list} (a list of per-refit item log tables). They are stored
on the state as \code{state$batch_log}, \code{state$config$round_log}, and
\code{state$logs$item_log_list}. When
\code{adaptive$v3$write_outputs = TRUE}, \code{batch_log.rds} and
\code{round_log.rds} are written to \code{output_dir}, and item logs are
written as \code{item_log_refit_0001.rds}, \code{item_log_refit_0002.rds},
etc. Summary helpers such as \code{summarize_iterations()},
\code{summarize_refits()}, and \code{summarize_items()} are pure views of
these tables.

Batch log columns (one row per iteration):
\describe{
\item{\code{iter}}{Iteration index (starting at 1).}
\item{\code{phase}}{Phase label: \code{"phase1"}, \code{"phase2"}, or
\code{"phase3"}.}
\item{\code{mode}}{Run mode: \code{"warm_start"}, \code{"adaptive"}, or
\code{"stopped"}.}
\item{\code{created_at}}{Timestamp when the iteration log row was created.}
\item{\code{batch_size_target}}{Target number of pairs for the iteration.}
\item{\code{n_pairs_selected}}{Pairs scheduled in this iteration.}
\item{\code{n_pairs_completed}}{New results observed since the previous
iteration log.}
\item{\code{n_pairs_failed}}{New failed attempts since the previous log.}
\item{\code{backlog_unjudged}}{Scheduled minus completed pairs after
scheduling.}
\item{\code{n_explore_target}}{Target exploration pairs in the batch.}
\item{\code{n_explore_selected}}{Exploration pairs scheduled.}
\item{\code{n_exploit_target}}{Target exploitation pairs in the batch.}
\item{\code{n_exploit_selected}}{Exploitation pairs scheduled.}
\item{\code{n_candidates_generated}}{Candidate pairs generated before
filtering.}
\item{\code{n_candidates_after_filters}}{Candidates remaining after
filtering (duplicates, degree, constraints).}
\item{\code{candidate_starved}}{TRUE when fewer than target pairs were
scheduled due to candidate scarcity.}
\item{\code{fallback_exhausted}}{TRUE when the fallback ladder was fully
exhausted without reaching the target batch size.}
\item{\code{fallback_used}}{Fallback mode used when starved (from
\code{.adaptive_fallback_used_levels()}).}
\item{\code{fallback_path}}{Fallback path taken for the iteration.}
\item{\code{a1_stage}}{Stage label for the first fallback attempt.}
\item{\code{a1_W_used}}{Window size used in stage 1.}
\item{\code{a1_anchor_pool}}{Anchor pool used in stage 1.}
\item{\code{a1_n_generated}}{Candidates generated in stage 1.}
\item{\code{a1_n_survive}}{Candidates surviving filters in stage 1.}
\item{\code{a1_n_selected}}{Pairs selected in stage 1.}
\item{\code{a2_stage}}{Stage label for the second fallback attempt.}
\item{\code{a2_W_used}}{Window size used in stage 2.}
\item{\code{a2_anchor_pool}}{Anchor pool used in stage 2.}
\item{\code{a2_n_generated}}{Candidates generated in stage 2.}
\item{\code{a2_n_survive}}{Candidates surviving filters in stage 2.}
\item{\code{a2_n_selected}}{Pairs selected in stage 2.}
\item{\code{a3_stage}}{Stage label for the third fallback attempt.}
\item{\code{a3_W_used}}{Window size used in stage 3.}
\item{\code{a3_anchor_pool}}{Anchor pool used in stage 3.}
\item{\code{a3_n_generated}}{Candidates generated in stage 3.}
\item{\code{a3_n_survive}}{Candidates surviving filters in stage 3.}
\item{\code{a3_n_selected}}{Pairs selected in stage 3.}
\item{\code{aN_tried}}{Number of fallback stages attempted.}
\item{\code{aN_best_stage}}{Best fallback stage selected.}
\item{\code{aN_best_n_generated}}{Candidates generated in best stage.}
\item{\code{aN_best_n_survive}}{Candidates surviving in best stage.}
\item{\code{aN_best_n_selected}}{Pairs selected in best stage.}
\item{\code{starvation_reason}}{Primary starvation reason label (from
\code{.adaptive_starvation_reason_levels()}).}
\item{\code{reason_short_batch}}{Human-readable reason for short batch.}
\item{\code{W_used}}{Window size actually used for selection.}
\item{\code{explore_rate_used}}{Exploration rate actually used.}
\item{\code{utility_selected_p50}}{Median utility of selected pairs.}
\item{\code{utility_selected_p90}}{90th percentile utility of selected
pairs.}
\item{\code{utility_candidate_p90}}{90th percentile utility of candidate
pool.}
\item{\code{iter_exit_path}}{Exit path label for the iteration.}
}

Round log columns (one row per refit, canonical stop audit trail):
\describe{
\item{\code{round_id}}{Refit index (starting at 1).}
\item{\code{iter_at_refit}}{Iteration index at refit time.}
\item{\code{mode}}{Run mode at refit.}
\item{\code{model_variant}}{Model variant label (see Model variants).}
\item{\code{n_items}}{Number of items in the run.}
\item{\code{total_pairs}}{Total unordered pairs, \eqn{N(N-1)/2}.}
\item{\code{hard_cap_threshold}}{Hard cap count based on
\code{hard_cap_frac}.}
\item{\code{n_unique_pairs_seen}}{Unique unordered pairs observed at least
once.}
\item{\code{scheduled_pairs}}{Total scheduled pairs.}
\item{\code{completed_pairs}}{Total observed results.}
\item{\code{backlog_unjudged}}{Scheduled minus completed at refit time.}
\item{\code{new_pairs}}{Pairs observed since the previous refit.}
\item{\code{proposed_pairs}}{Candidate pairs evaluated at refit time.}
\item{\code{batch_size}}{Batch size target in effect at refit.}
\item{\code{window_W}}{Window size used for candidate generation.}
\item{\code{exploration_rate}}{Exploration rate used for candidate mixes.}
\item{\code{mean_degree}}{Mean item degree at refit.}
\item{\code{min_degree}}{Minimum item degree at refit.}
\item{\code{pos_balance_mean}}{Mean position balance across items.}
\item{\code{pos_balance_sd}}{SD of position balance across items.}
\item{\code{mean_degree_scheduled}}{Mean item degree based on scheduled
pairs (\code{history_pairs}).}
\item{\code{min_degree_scheduled}}{Minimum item degree based on scheduled
pairs (\code{history_pairs}).}
\item{\code{pos_balance_sd_scheduled}}{SD of position A share based on
scheduled pairs, computed as \code{posA_scheduled / pmax(deg_scheduled, 1)}.}
\item{\code{epsilon_mean}}{Posterior mean of epsilon (NA if absent).}
\item{\code{epsilon_p2.5}}{2.5th percentile of epsilon (NA if absent).}
\item{\code{epsilon_p5}}{5th percentile of epsilon (NA if absent).}
\item{\code{epsilon_p50}}{Median epsilon (NA if absent).}
\item{\code{epsilon_p95}}{95th percentile of epsilon (NA if absent).}
\item{\code{epsilon_p97.5}}{97.5th percentile of epsilon (NA if absent).}
\item{\code{beta_mean}}{Posterior mean of beta (NA if absent).}
\item{\code{beta_p2.5}}{2.5th percentile of beta (NA if absent).}
\item{\code{beta_p5}}{5th percentile of beta (NA if absent).}
\item{\code{beta_p50}}{Median beta (NA if absent).}
\item{\code{beta_p95}}{95th percentile of beta (NA if absent).}
\item{\code{beta_p97.5}}{97.5th percentile of beta (NA if absent).}
\item{\code{divergences}}{Total divergences reported by MCMC.}
\item{\code{max_rhat}}{Maximum R-hat across parameters.}
\item{\code{min_ess_bulk}}{Minimum bulk ESS across parameters.}
\item{\code{diagnostics_pass}}{Diagnostics gate status.}
\item{\code{reliability_EAP}}{EAP reliability statistic.}
\item{\code{theta_sd_eap}}{SD of theta means at refit.}
\item{\code{rho_theta_lag}}{Pearson correlation between current and lagged
theta means (\code{NA} when \code{lag_eligible = FALSE}).}
\item{\code{delta_sd_theta_lag}}{Relative change in theta SD vs lagged
refit (\code{NA} when \code{lag_eligible = FALSE}).}
\item{\code{rho_rank_lag}}{Spearman correlation between current and lagged
ranks (\code{NA} when \code{lag_eligible = FALSE}).}
\item{\code{eap_pass}}{TRUE when diagnostics pass and EAP reliability meets
\code{eap_reliability_min}; \code{NA} when \code{diagnostics_pass} is FALSE
or \code{NA}.}
\item{\code{theta_corr_pass}}{TRUE when lagged theta correlation meets
\code{theta_corr_min}; \code{NA} when \code{lag_eligible = FALSE}.}
\item{\code{delta_sd_theta_pass}}{TRUE when lagged theta SD change meets
\code{theta_sd_rel_change_max}; \code{NA} when \code{lag_eligible = FALSE}.}
\item{\code{rho_rank_pass}}{TRUE when lagged rank correlation meets
\code{rank_spearman_min}; \code{NA} when \code{lag_eligible = FALSE}.}
\item{\code{rank_stability_pass}}{Rank stability gate status
(\code{NA} when \code{lag_eligible = FALSE}).}
\item{\code{lag_eligible}}{TRUE when lagged stability checks are eligible
(current refit exceeds \code{stability_lag}).}
\item{\code{stop_decision}}{TRUE when stop criteria are met.}
\item{\code{stop_reason}}{Stop reason label when stopped.}
\item{\code{starve_rate_since_last_refit}}{Fraction of iterations since
last refit that were candidate-starved.}
\item{\code{fallback_rate_since_last_refit}}{Fraction of iterations since
last refit that used fallback selection.}
\item{\code{fallback_used_mode}}{Most frequent fallback mode since last
refit.}
\item{\code{starvation_reason_mode}}{Most frequent starvation reason since
last refit.}
\item{\code{mcmc_chains}}{Number of MCMC chains used.}
\item{\code{mcmc_parallel_chains}}{Number of chains run in parallel.}
\item{\code{mcmc_core_fraction}}{Core fraction used to size parallel
chains.}
\item{\code{mcmc_cores_detected_physical}}{Detected physical cores.}
\item{\code{mcmc_cores_detected_logical}}{Detected logical cores.}
\item{\code{mcmc_threads_per_chain}}{Threads per chain (if set).}
\item{\code{mcmc_cmdstanr_version}}{CmdStanR version used for the refit.}
}

Item log columns (one row per item per refit):
\describe{
\item{\code{ID}}{Item identifier.}
\item{\code{deg}}{Observed degree (total comparisons involving the item).}
\item{\code{posA_prop}}{Share of comparisons where the item appeared in
position A.}
\item{\code{theta_mean}}{Posterior mean of item strength.}
\item{\code{theta_p2.5}}{2.5th percentile of theta.}
\item{\code{theta_p5}}{5th percentile of theta.}
\item{\code{theta_p50}}{Median theta.}
\item{\code{theta_p95}}{95th percentile of theta.}
\item{\code{theta_p97.5}}{97.5th percentile of theta.}
\item{\code{theta_sd}}{Posterior SD of theta.}
\item{\code{rank_mean}}{Mean induced rank (lower is better).}
\item{\code{rank_p2.5}}{2.5th percentile of rank.}
\item{\code{rank_p5}}{5th percentile of rank.}
\item{\code{rank_p50}}{Median rank.}
\item{\code{rank_p95}}{95th percentile of rank.}
\item{\code{rank_p97.5}}{97.5th percentile of rank.}
\item{\code{rank_sd}}{Posterior SD of rank.}
}
}

\examples{
# Minimal synthetic setup (no submission).
samples <- tibble::tibble(
  ID = c("S1", "S2", "S3", "S4"),
  text = c("alpha", "bravo", "charlie", "delta")
)
td <- trait_description("overall_quality")
adaptive_cfg <- list(d1 = 8, M1_target = 40)

# Stop-criteria presets (copy/paste ready)
adaptive_fast <- list(
  v3 = list(
    eap_reliability_min = 0.80,
    min_ess_bulk = 150,
    max_rhat = 1.05
  )
)
adaptive_high_conf <- list(
  v3 = list(
    eap_reliability_min = 0.95,
    min_ess_bulk = 1000,
    max_rhat = 1.01
  )
)
adaptive_debug <- list(
  v3 = list(
    progress = TRUE,
    progress_level = "full"
  )
)

\dontrun{
# Live start (submits immediately and ingests observed results)
start_out <- adaptive_rank_start(
  samples = samples,
  model = "gpt-4.1",
  trait_name = td$name,
  trait_description = td$description,
  backend = "openai",
  mode = "live",
  adaptive = adaptive_fast,
  seed = 123
)

# Live resume (continues scheduling; may require multiple calls)
resume_out <- adaptive_rank_resume(
  state = start_out$state,
  mode = "live",
  submission_info = start_out$submission_info,
  adaptive = adaptive_high_conf,
  seed = 123
)

# Batch start (submits jobs and returns resume info)
batch_out <- adaptive_rank_start(
  samples = samples,
  model = "gpt-4.1",
  trait_name = td$name,
  trait_description = td$description,
  backend = "openai",
  mode = "batch",
  submission = list(batch_size = 1000, write_registry = TRUE),
  paths = list(output_dir = "adaptive_runs"),
  adaptive = adaptive_debug,
  seed = 123
)

# Batch resume loop (poll until done)
next_action <- batch_out$next_action
state <- batch_out$state
submission_info <- batch_out$submission_info
while (identical(next_action$action, "resume")) {
  res <- adaptive_rank_resume(
    state = state,
    mode = "batch",
    submission_info = submission_info,
    adaptive = adaptive_cfg,
    seed = 123
  )
  state <- res$state
  submission_info <- res$submission_info
  next_action <- res$next_action
}
}

}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/openai_live.R
\name{submit_openai_pairs_live}
\alias{submit_openai_pairs_live}
\title{Live OpenAI comparisons for a tibble of pairs}
\usage{
submit_openai_pairs_live(
  pairs,
  model,
  trait_name,
  trait_description,
  prompt_template = set_prompt_template(),
  endpoint = c("chat.completions", "responses"),
  api_key = NULL,
  verbose = TRUE,
  status_every = 1,
  progress = interactive(),
  include_raw = FALSE,
  validate = FALSE,
  validate_strict = FALSE,
  save_path = NULL,
  parallel = FALSE,
  workers = 1,
  ...
)
}
\arguments{
\item{pairs}{Tibble or data frame with at least columns \code{ID1},
\code{text1}, \code{ID2}, \code{text2}. Typically created by
\code{\link{make_pairs}}, \code{\link{sample_pairs}}, and
\code{\link{randomize_pair_order}}.}

\item{model}{OpenAI model name (for example "gpt-4.1", "gpt-5.1").}

\item{trait_name}{Trait name to pass to \code{openai_compare_pair_live}.}

\item{trait_description}{Trait description to pass to
\code{openai_compare_pair_live}.}

\item{prompt_template}{Prompt template string, typically from
\code{\link{set_prompt_template}}.}

\item{endpoint}{Which OpenAI endpoint to target. One of
\code{"chat.completions"} or \code{"responses"}.}

\item{api_key}{Optional OpenAI API key.}

\item{verbose}{Logical; if TRUE, prints status, timing, and result summaries.}

\item{status_every}{Integer; print status / timing for every
\code{status_every}-th pair. Defaults to 1 (every pair).}

\item{progress}{Logical; if TRUE, shows a textual progress bar.}

\item{include_raw}{Logical; if TRUE, each row of the returned tibble will
include a \code{raw_response} list-column with the parsed JSON body from
OpenAI. Note: Raw responses are not saved to the incremental CSV file.}

\item{validate}{Logical; if \code{TRUE}, attach a compact \code{validation_report} computed by \code{\link[=validate_backend_results]{validate_backend_results()}}.}

\item{validate_strict}{Logical; only used when \code{validate = TRUE}. If \code{TRUE}, enforce validity by calling \code{\link[=validate_pairwise_results]{validate_pairwise_results()}} (errors on invalid winners). If \code{FALSE} (default), validation is report-only.}

\item{save_path}{Character string; optional file path (e.g., "output.csv")
to save results incrementally. If the file exists, the function reads it
to identify and skip pairs that have already been processed (resume mode).
Requires the \code{readr} package.}

\item{parallel}{Logical; if TRUE, enables parallel processing using
\code{future.apply}. Requires the \code{future} and \code{future.apply}
packages.}

\item{workers}{Integer; the number of parallel workers (threads) to use if
\code{parallel = TRUE}. Defaults to 1.
\strong{Guidance:} A value between 4 and 8 is usually safe. Setting this
too high (e.g., >20) may trigger OpenAI rate limit errors (HTTP 429)
depending on your usage tier.}

\item{...}{Additional OpenAI parameters (temperature, top_p, logprobs,
reasoning, and so on) passed on to \code{openai_compare_pair_live}.}
}
\value{
A list containing two elements:
\describe{
\item{results}{A tibble with one row per successfully processed pair and
columns such as \code{better_id}, \code{better_sample}, \code{thoughts},
and \code{content}. See \code{\link{openai_compare_pair_live}} for
details.}
\item{failed_pairs}{A tibble containing the rows from \code{pairs} that
failed to process (due to API errors or timeouts), along with an
\code{error_message} column. These can be easily re-submitted.}
}
}
\description{
This is a robust row-wise wrapper around
\code{\link{openai_compare_pair_live}}. It takes a tibble of pairs
(ID1 / text1 / ID2 / text2), submits each pair to the OpenAI API, and
collects the results.
}
\details{
This function improves upon simple looping by offering:
\itemize{
\item \strong{Parallel Processing:} Uses the \code{future} package to process
multiple pairs simultaneously.
\item \strong{Incremental Saving:} Writes results to a CSV file as they complete.
If the process is interrupted, re-running the function with the same
\code{save_path} will automatically skip pairs that were already successfully processed.
\item \strong{Error Separation:} Returns valid results and failed pairs separately,
making it easier to debug or retry specific failures.
}
}
\examples{
\dontrun{
# Requires API key set and internet access

data("example_writing_samples", package = "pairwiseLLM")

pairs <- example_writing_samples |>
  make_pairs() |>
  sample_pairs(n_pairs = 10, seed = 123) |>
  randomize_pair_order(seed = 456)

td <- trait_description("overall_quality")
tmpl <- set_prompt_template()

# 1. Sequential execution with incremental saving
# If interrupted, running this again will resume progress.
res_seq <- submit_openai_pairs_live(
  pairs             = pairs,
  model             = "gpt-4.1",
  trait_name        = td$name,
  trait_description = td$description,
  prompt_template   = tmpl,
  save_path         = "results_seq.csv"
)

# 2. Parallel execution (faster)
# Note: On Windows, this opens background R sessions.
res_par <- submit_openai_pairs_live(
  pairs             = pairs,
  model             = "gpt-4.1",
  trait_name        = td$name,
  trait_description = td$description,
  save_path         = "results_par.csv",
  parallel          = TRUE,
  workers           = 4
)

# Inspect results
head(res_par$results)

# Check for failures
if (nrow(res_par$failed_pairs) > 0) {
  message("Some pairs failed:")
  print(res_par$failed_pairs)
}
}

}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bt_run_adaptive_core_linking.R
\name{bt_run_adaptive_core_linking}
\alias{bt_run_adaptive_core_linking}
\title{Run an adaptive core-linking BT workflow end-to-end}
\usage{
bt_run_adaptive_core_linking(
  samples,
  batches,
  judge_fun,
  core_ids = NULL,
  core_method = c("auto", "pam", "clara", "embeddings", "token_stratified", "random"),
  core_size = NULL,
  core_pct = NULL,
  embeddings = NULL,
  embeddings_metric = c("cosine", "euclidean"),
  linking = c("auto", "always", "never"),
  linking_method = c("median_iqr", "median_mad", "mean_sd"),
  linking_cor_target = 0.98,
  linking_p90_abs_shift_target = 0.15,
  linking_max_abs_shift_target = 0.3,
  linking_min_n = 3L,
  reference_scale_method = c("median_iqr", "median_mad", "mean_sd"),
  reference_max_abs = 6,
  seed_core = NULL,
  initial_results = NULL,
  judge = NULL,
  engine = "sirt",
  fit_verbose = FALSE,
  return_diagnostics = TRUE,
  include_residuals = FALSE,
  fit_engine_running = c("bt", "rank_centrality"),
  store_running_estimates = TRUE,
  rc_smoothing = 0.5,
  rc_damping = 0,
  final_refit = TRUE,
  final_bt_bias_reduction = TRUE,
  round_size = 50,
  init_round_size = round_size,
  max_rounds_per_batch = 50,
  within_batch_frac = 0.25,
  core_audit_frac = 0.05,
  allocation = c("fixed", "precision_ramp", "audit_on_drift"),
  allocation_fun = NULL,
  k_neighbors = 10,
  min_judgments = 12,
  forbid_repeats = TRUE,
  balance_positions = TRUE,
  seed = NULL,
  seed_pairs = NULL,
  se_probs = c(0.5, 0.9, 0.95),
  fit_bounds = c(0.7, 1.3),
  stopping_tier = c("strong", "good", "very_strong"),
  reliability_target = 0.9,
  sepG_target = 3,
  rel_se_p90_target = 0.3,
  rel_se_p90_min_improve = 0.01,
  max_item_misfit_prop = 0.05,
  max_judge_misfit_prop = 0.05,
  core_theta_cor_target = NA_real_,
  core_theta_spearman_target = NA_real_,
  core_max_abs_shift_target = NA_real_,
  core_p90_abs_shift_target = NA_real_,
  checkpoint_dir = NULL,
  resume_from = NULL,
  checkpoint_every = 1L,
  checkpoint_store_fits = TRUE,
  checkpoint_overwrite = TRUE,
  fit_fun = fit_bt_model,
  build_bt_fun = function(results, judge = NULL, ...) {
     build_bt_data(results, ...)

    },
  ...
)
}
\arguments{
\item{samples}{A tibble/data.frame with columns \code{ID} and \code{text}. \code{ID}
must be unique and non-missing.}

\item{batches}{A list defining the batches of new IDs to add. Each element should
be a character vector of IDs. A single character vector is treated as one batch.
IDs must be present in \code{samples$ID}.}

\item{judge_fun}{A function that accepts a tibble of pairs with columns
\code{ID1}, \code{text1}, \code{ID2}, \code{text2} and returns a tibble with
columns \code{ID1}, \code{ID2}, and \code{better_id}. If \code{judge} is provided,
the returned tibble must also include that judge column.}

\item{core_ids}{Optional character vector of core IDs. If \code{NULL}, core IDs are
selected using \code{core_method} and sizing arguments.}

\item{core_method}{Method passed to \code{\link{select_core_set}} when \code{core_ids}
is \code{NULL}. One of \code{"auto"}, \code{"pam"}, \code{"clara"},
\code{"embeddings"} (alias for \code{"auto"}), \code{"token_stratified"},
or \code{"random"}.}

\item{core_size}{Optional integer core size passed to \code{\link{select_core_set}}.}

\item{core_pct}{Optional numeric core proportion passed to \code{\link{select_core_set}}.}

\item{embeddings}{Optional embedding matrix passed to \code{\link{select_core_set}} when
using embeddings-based core selection (\code{core_method} in
\code{c("auto","pam","clara","embeddings")}).}

\item{embeddings_metric}{Distance metric for embeddings selection. Passed to
\code{\link{select_core_set}}.}

\item{linking}{Whether to apply anchoring/linking so theta estimates are reported
on a stable scale defined by the baseline core fit. One of
\code{"auto"}, \code{"always"}, or \code{"never"}. In \code{"auto"},
linking is applied only when core drift exceeds the thresholds below.}

\item{linking_method}{Linking method passed to \code{\link[=bt_link_thetas]{bt_link_thetas()}}.
\itemize{
\item \code{"mean_sd"}: match mean and SD on the core set.
\item \code{"median_iqr"}: match median and a robust SD estimate based on IQR.
\item \code{"median_mad"}: match median and a robust SD estimate based on MAD.
}
Robust methods are strongly recommended for real-world adaptive runs because
early rounds can be close to deterministic (separation).}

\item{linking_cor_target}{In \code{linking = "auto"}, apply linking when the core
Pearson correlation between baseline and current raw thetas is below this value.}

\item{linking_p90_abs_shift_target}{In \code{linking = "auto"}, apply linking when the
90th percentile of the absolute core-theta shift (baseline vs current raw) exceeds
this value.}

\item{linking_max_abs_shift_target}{In \code{linking = "auto"}, apply linking when the
maximum absolute core-theta shift (baseline vs current raw) exceeds this value.}

\item{linking_min_n}{Minimum number of core IDs required to estimate the linking
transform. If fewer are available, linking is skipped.}

\item{reference_scale_method}{Method used to stabilize the \emph{reference} (baseline)
theta scale before it is used for linking decisions. Defaults to a robust
median/IQR-based scale. This reduces pathological behavior when the early core
fit is close to deterministic (separation), which can otherwise cause linking
scale factors to explode.}

\item{reference_max_abs}{Maximum absolute value allowed for reference thetas after
stabilization (clamping). This is applied only to the reference fit used for
linking/drift diagnostics.}

\item{seed_core}{Optional integer seed for reproducible core selection.}

\item{initial_results}{Optional tibble/data.frame of already-scored pairs with columns
\code{ID1}, \code{ID2}, \code{better_id} (and optional judge column). These results are
used as the starting state.}

\item{judge}{Optional character scalar giving the name of the column in results that
identifies the judge/backend/model.}

\item{engine}{Character scalar passed to \code{fit_fun} as its \code{engine} argument.
Default \code{"sirt"}.}

\item{fit_verbose}{Logical; passed to \code{fit_fun} as \code{verbose}. Default \code{FALSE}.}

\item{return_diagnostics}{Logical; passed to \code{fit_fun}. Default \code{TRUE}.}

\item{include_residuals}{Logical; passed to \code{fit_fun}. Default \code{FALSE}.}

\item{fit_engine_running}{Running fitting engine used to propose the \emph{next} round
of pairs. One of \code{"bt"} (use BT thetas; default) or \code{"rank_centrality"}
(use Rank Centrality scores as the running theta while retaining BT standard
errors for uncertainty-driven sampling).}

\item{store_running_estimates}{Logical; if TRUE, store the running-fit object
in \code{out$fits}. If FALSE, store the BT fit.}

\item{rc_smoothing}{Numeric smoothing parameter forwarded to
\code{\link{fit_rank_centrality}} when \code{fit_engine_running="rank_centrality"}
or when final refit computes Rank Centrality. Default \code{0.5}.}

\item{rc_damping}{Numeric damping/teleport parameter in \code{[0,1)} forwarded to
\code{\link{fit_rank_centrality}}. Use \code{>0} for unique stationary
distributions on disconnected graphs. Default \code{0}.}

\item{final_refit}{Logical; if TRUE (default), compute final BT and Rank Centrality
estimates on the full result set via \code{\link{compute_final_estimates}} and
return them as \code{out$estimates}.}

\item{final_bt_bias_reduction}{Logical; if TRUE (default), attempt bias-reduced
BT fitting (Firth / br=TRUE) in the final refit (falls back to MLE if unavailable).}

\item{round_size}{Integer. Number of new pairs to propose and score per round within each
batch.}

\item{init_round_size}{Integer. Number of bootstrap pairs to score on the core set before
processing batches, when no \code{initial_results} are supplied. Default \code{round_size}.}

\item{max_rounds_per_batch}{Integer. Maximum number of rounds per batch. Default \code{50}.}

\item{within_batch_frac}{Numeric in \code{[0,1]}. Fraction of non-audit pairs allocated to new\eqn{\leftrightarrow}new
within-batch comparisons (passed to \code{\link{select_core_link_pairs}}).}

\item{core_audit_frac}{Numeric in \code{[0,1]}. Fraction of pairs allocated to core\eqn{\leftrightarrow}core audits
(passed to \code{\link{select_core_link_pairs}}).}

\item{allocation}{Allocation preset controlling how within-batch and auditing
fractions may be adjusted between rounds. One of \code{"fixed"}, \code{"precision_ramp"},
or \code{"audit_on_drift"}. If \code{allocation_fun} is supplied, it takes precedence
and \code{allocation} is ignored.}

\item{allocation_fun}{Optional function to update \code{within_batch_frac} and/or \code{core_audit_frac}
between rounds. It is called after metrics are computed each round with a state list and
should return NULL (no change) or a list with elements \code{within_batch_frac} and/or
\code{core_audit_frac}.}

\item{k_neighbors}{Integer. Passed to \code{\link{select_core_link_pairs}}.}

\item{min_judgments}{Integer. Passed to \code{\link{select_core_link_pairs}}.}

\item{forbid_repeats}{Logical. Passed to \code{\link{select_core_link_pairs}}.}

\item{balance_positions}{Logical. Passed to \code{\link{select_core_link_pairs}}.}

\item{seed}{Optional integer alias for \code{seed_pairs} (backwards compatibility).
Prefer \code{seed_pairs} going forward.}

\item{seed_pairs}{Optional integer seed used for bootstrap pair sampling and for each round
as \code{seed_pairs + batch_index*1000 + round_index}. RNG state is restored afterward.}

\item{se_probs}{Numeric vector of probabilities in (0,1) for SE quantiles (passed to
\code{\link{bt_stop_metrics}}).}

\item{fit_bounds}{Numeric length-2 vector giving acceptable infit/outfit bounds
(infit/outfit) passed to \code{\link{bt_stop_metrics}}.}

\item{stopping_tier}{Preset stopping thresholds to use (\code{"good"},
\code{"strong"}, \code{"very_strong"}). Passed to
\code{\link{bt_stop_metrics}}.}

\item{reliability_target, sepG_target, rel_se_p90_target, rel_se_p90_min_improve, max_item_misfit_prop, max_judge_misfit_prop}{Stopping thresholds passed to \code{\link{bt_should_stop}}.}

\item{core_theta_cor_target, core_theta_spearman_target, core_max_abs_shift_target, core_p90_abs_shift_target}{Optional drift guardrails passed to \code{\link{bt_should_stop}}. If any of these are not
\code{NA}, the runner computes core drift metrics per round by comparing the current fit to
the prior batch's final fit (or the bootstrap fit for the first batch).}

\item{checkpoint_dir}{Optional directory path for writing checkpoint files during
the run. If provided, the runner writes \code{run_state.rds} (and optionally
per-round snapshot files) after completed rounds and/or batch boundaries. Use
this to resume long jobs after interruption or errors.}

\item{resume_from}{Optional directory path containing a prior checkpoint file
\code{run_state.rds} created by \code{bt_run_adaptive_core_linking()}. When
provided, the run resumes from the saved state, including accumulated results,
batch/round indices, and stopping/metrics history. The \code{samples}, batch
definitions, and \code{core_ids} must be compatible with the checkpoint.}

\item{checkpoint_every}{Integer controlling how frequently per-round snapshot
files are written. A value of \code{1} writes a snapshot after every completed
round; a value of \code{2} writes snapshots every other round, etc. The main
file \code{run_state.rds} is still updated at safe points even when
\code{checkpoint_every > 1}.}

\item{checkpoint_store_fits}{Logical indicating whether to store fitted model
objects (BT fits and diagnostics) inside checkpoint files. Set to \code{FALSE}
to reduce checkpoint size; fits may be recomputed after resuming.}

\item{checkpoint_overwrite}{Logical indicating whether to overwrite an existing
\code{run_state.rds} file in \code{checkpoint_dir}. If \code{FALSE} and a
checkpoint already exists, the function should error rather than overwrite.}

\item{fit_fun}{Function used to fit the BT model. Default \code{\link{fit_bt_model}}.
Primarily intended as a test hook.}

\item{build_bt_fun}{Function used to convert results into BT data. Default
\code{\link{build_bt_data}}. Primarily intended as a test hook.}

\item{...}{Additional arguments passed through to \code{fit_fun}.}
}
\value{
A list with:
\describe{
\item{core_ids}{Core linking IDs used.}
\item{batches}{Normalized batches list.}
\item{results}{All judged results (canonicalized \code{better_id}).}
\item{bt_data}{BT data built from \code{results}.}
\item{fits}{List of per-round fits (including the initial bootstrap fit, if any). Each
fit is tagged with per-round metadata in the
\code{attr(fit, "bt_run_adaptive_core_linking")} attribute.}
\item{final_fits}{Named list of final fit per batch (plus \code{"bootstrap"} when
applicable).}
\item{metrics}{Tibble of stop metrics per round (computed on each batch's new IDs).}
\item{batch_summary}{One row per batch: rounds used, stop reason, counts.}
\item{state}{A tibble with one row per scoring round containing bookkeeping summaries of
accumulated results (overall and for the current batch's new IDs). New-ID fields are
prefixed with \code{new_}. Rows include \code{batch_index}, \code{round_index}, and
\code{stage}.}
}
}
\description{
This exported runner implements the "hybrid" workflow that combines:
\itemize{
\item a stable core linking bank (anchors),
\item adding new samples in batches, and
\item round-based adaptive pair selection within each batch.
}
}
\details{
The loop for each batch is:
\enumerate{
\item Propose a round of pairs using \code{\link{bt_core_link_round}} (core\eqn{\leftrightarrow}new linking,
optional new\eqn{\leftrightarrow}new within-batch comparisons, and optional core\eqn{\leftrightarrow}core audit pairs).
\item Score those pairs via \code{judge_fun} and append results.
\item Fit a BT model (default: \code{\link{fit_bt_model}}).
\item Compute stopping metrics on the batch's new IDs via \code{\link{bt_stop_metrics}}
and decide whether to stop via \code{\link{bt_should_stop}}.
\item Repeat until stopping criteria are met, no new pairs can be proposed, or
\code{max_rounds_per_batch} is reached.
}

If \code{core_ids} is \code{NULL}, the core set can be selected from \code{samples}
using \code{\link{select_core_set}}.

\strong{Checkpointing and resuming:} If \code{checkpoint_dir} is provided, this
function writes a checkpoint at the last completed safe point (typically after a
round completes within a batch, and at batch boundaries). If an error occurs
mid-round, the checkpoint reflects the most recently completed round. Resume by
calling again with \code{resume_from = checkpoint_dir}.
}
\examples{
# Simple simulated judge: higher true theta wins
samples <- tibble::tibble(
  ID = LETTERS[1:8],
  text = paste0("t", LETTERS[1:8])
)
true_theta <- stats::setNames(seq(2, -1.5, length.out = 8), samples$ID)

judge_fun <- function(pairs) {
  b <- ifelse(true_theta[pairs$ID1] >= true_theta[pairs$ID2], pairs$ID1, pairs$ID2)
  tibble::tibble(ID1 = pairs$ID1, ID2 = pairs$ID2, better_id = b)
}

# Mock BT fitter: theta = centered win counts, se = 1/sqrt(judgments)
fit_fun <- function(bt_data, ...) {
  bt_data <- tibble::as_tibble(bt_data)
  ids <- sort(unique(c(bt_data$object1, bt_data$object2)))
  wins <- stats::setNames(rep(0L, length(ids)), ids)
  n_j <- stats::setNames(rep(0L, length(ids)), ids)
  for (i in seq_len(nrow(bt_data))) {
    a <- bt_data$object1[[i]]
    b <- bt_data$object2[[i]]
    r <- bt_data$result[[i]]
    if (isTRUE(is.finite(r))) {
      if (r == 1) wins[a] <- wins[a] + 1L else wins[b] <- wins[b] + 1L
      n_j[a] <- n_j[a] + 1L
      n_j[b] <- n_j[b] + 1L
    }
  }
  theta <- as.numeric(wins - stats::median(wins))
  se <- 1 / sqrt(pmax(1L, as.integer(n_j)))
  list(
    engine = "mock",
    reliability = 0.95,
    theta = tibble::tibble(ID = names(wins), theta = theta, se = se),
    diagnostics = list(sepG = 3.5)
  )
}

out <- bt_run_adaptive_core_linking(
  samples = samples,
  batches = list(c("G", "H")),
  judge_fun = judge_fun,
  core_ids = c("A", "B", "C"),
  fit_fun = fit_fun,
  engine = "mock",
  round_size = 6,
  init_round_size = 6,
  max_rounds_per_batch = 2,
  rel_se_p90_target = 0.7,
  reliability_target = NA_real_,
  sepG_target = NA_real_,
  rel_se_p90_min_improve = NA_real_,
  max_item_misfit_prop = NA_real_,
  max_judge_misfit_prop = NA_real_
)
out$batch_summary

}

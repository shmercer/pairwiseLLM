% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_multi_batch.R
\name{llm_resume_multi_batches}
\alias{llm_resume_multi_batches}
\title{Resume polling and download results for multiple batch jobs}
\usage{
llm_resume_multi_batches(
  jobs = NULL,
  output_dir = NULL,
  interval_seconds = 60,
  per_job_delay = 2,
  write_results_csv = FALSE,
  keep_jsonl = TRUE,
  write_registry = FALSE,
  tag_prefix = "<BETTER_SAMPLE>",
  tag_suffix = "</BETTER_SAMPLE>",
  verbose = FALSE,
  write_combined_csv = FALSE,
  combined_csv_path = NULL,
  openai_max_retries = 3,
  validate = FALSE,
  validate_strict = FALSE,
  normalize_winner = FALSE,
  max_rounds = NULL
)
}
\arguments{
\item{jobs}{A list of job objects returned by
\code{\link[=llm_submit_pairs_multi_batch]{llm_submit_pairs_multi_batch()}}.  If \code{NULL}, a registry CSV is loaded
from \code{output_dir} and converted into an internal jobs structure.}

\item{output_dir}{Directory containing the batch files and (optionally) the
registry CSV.  If \code{jobs} is \code{NULL}, this directory must be supplied so
that the registry can be loaded.  When \code{jobs} is provided and
\code{output_dir} is \code{NULL}, the directory is inferred from the first job’s
\code{batch_output_path}.  When writing results CSVs or updating the registry,
this directory is used.}

\item{interval_seconds}{Number of seconds to wait between rounds of polling
unfinished batches.  The default (\code{60}) mirrors the example in the
advanced vignette.}

\item{per_job_delay}{Number of seconds to wait between polling individual
jobs within a single round.  A small delay (e.g. 2) can help prevent 429
(Too Many Requests) responses.}

\item{write_results_csv}{Logical; if \code{TRUE}, each batch’s parsed results are
written to a CSV file (\code{csv_path}) in \code{output_dir} as soon as they are
available.  If \code{FALSE} (the default), results are kept in memory.}

\item{keep_jsonl}{Logical; if \code{FALSE}, the \code{.jsonl} input and output files
will be deleted after the job results have been parsed.  Defaults to \code{TRUE}.}

\item{write_registry}{Logical; if \code{TRUE}, a CSV registry of batch jobs
will be written (or updated) at the end of polling.  When reading
jobs from a saved registry via \code{output_dir}, this argument can be used
to control whether the registry is refreshed on disk as job statuses
change.  Defaults to \code{FALSE}.  See \code{\link[=llm_submit_pairs_multi_batch]{llm_submit_pairs_multi_batch()}} for
additional details on the registry format.}

\item{tag_prefix, tag_suffix}{Character strings passed to
\code{\link[=parse_anthropic_batch_output]{parse_anthropic_batch_output()}} and \code{\link[=parse_gemini_batch_output]{parse_gemini_batch_output()}}.  These
tags mark the start and end of the “better” sample in each provider’s
output.  The defaults match those used in the vignette.}

\item{verbose}{Logical; if \code{TRUE}, prints progress messages during
polling and result processing.  Messages include the batch ID, provider,
and current state on each polling round, as well as summary messages
when combined results are written to disk.  Defaults to \code{FALSE}.}

\item{write_combined_csv}{Logical; if \code{TRUE}, the combined results tibble
returned by the function will also be written to a CSV file.  The path
to write this file is determined by \code{combined_csv_path}.  Defaults to
\code{FALSE}.}

\item{combined_csv_path}{Optional file path for the combined results CSV.
If \code{write_combined_csv = TRUE} and \code{combined_csv_path} is \code{NULL}, the
combined results will be written to
\code{file.path(output_dir, "combined_results.csv")}.  When a non‑NULL
value is supplied, it is treated as an absolute path if it begins with
“/”, “~/”, or a Windows drive letter (e.g. “C:”), or if it contains a
directory component (i.e. \code{dirname(combined_csv_path) != "."}).  In that
case it will be used exactly as given.  Otherwise the file name is
assumed to be relative to \code{output_dir}.  This argument is ignored when
\code{write_combined_csv = FALSE}.}

\item{openai_max_retries}{Integer giving the maximum number of times to
retry certain OpenAI API calls when a transient HTTP 5xx error occurs.
In particular, when downloading batch output with
\code{\link[=openai_download_batch_output]{openai_download_batch_output()}}, the function will attempt to fetch
the output file up to \code{openai_max_retries} times if an
\code{httr2_http_500} error is raised.  Between retries the function sleeps
for \code{per_job_delay} seconds.  Set to a small positive value (e.g. 3)
to automatically recover from occasional server errors.  Defaults to 3.}

\item{validate}{Logical; if \code{TRUE}, attach a compact \code{validation_report} to the output (computed by \code{\link[=validate_backend_results]{validate_backend_results()}}). For \code{llm_submit_pairs_multi_batch()} this value is recorded in the job metadata so that downstream workflows can apply consistent validation defaults.}

\item{validate_strict}{Logical; only used when \code{validate = TRUE}. If \code{TRUE}, enforce validity by calling \code{\link[=validate_pairwise_results]{validate_pairwise_results()}} (errors on invalid winners). If \code{FALSE} (default), validation is report-only.}

\item{normalize_winner}{Logical; only used when \code{validate = TRUE}. If \code{TRUE}, normalize common winner tokens before validating (see \code{\link[=validate_backend_results]{validate_backend_results()}}).}

\item{max_rounds}{Optional integer; maximum number of polling rounds before stopping with an error. If \code{NULL} (default), a conservative cap is applied only when \code{interval_seconds == 0} and \code{per_job_delay == 0}.}
}
\value{
A list with two elements: \code{jobs}, the updated jobs list with each
element containing parsed results and a \code{done} flag, and \code{combined},
a tibble obtained by binding all completed results (\code{NULL} if no batches
completed).  If \code{write_results_csv} is \code{TRUE}, the combined tibble is still
returned in memory.
If \code{write_combined_csv} is \code{TRUE}, the combined tibble is also written
to a CSV file on disk (see \code{combined_csv_path} for details) but is still
returned in memory.
}
\description{
This function takes the output of \code{\link[=llm_submit_pairs_multi_batch]{llm_submit_pairs_multi_batch()}} (or a
previously written registry CSV) and polls each batch until completion,
downloading and parsing results as they finish.  It implements a
conservative polling loop with a configurable interval between rounds and
a small delay between individual jobs to reduce the risk of API rate‑limit
errors.  The httr2 retry wrapper is still invoked for each API call, so
transient HTTP errors will be retried with exponential back‑off.
}
\examples{
# Continuing the example from llm_submit_pairs_multi_batch():
# After submitting multiple batches, resume polling and combine the results.
\dontrun{
# Suppose `outdir` is the directory where batch files were written and
# `jobs` is the list of job metadata returned by llm_submit_pairs_multi_batch().

results <- llm_resume_multi_batches(
  jobs               = jobs,
  output_dir         = outdir,
  interval_seconds   = 60,
  per_job_delay      = 2,
  write_results_csv  = TRUE,
  keep_jsonl         = FALSE,
  write_registry     = TRUE,
  verbose            = TRUE,
  write_combined_csv = TRUE
)

# The combined results are available in the `combined` element
print(results$combined)
}

}

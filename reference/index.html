<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Package index • pairwiseLLM</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Package index"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">pairwiseLLM</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.2.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../index.html">Home</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-usage-guides" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Usage Guides</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-usage-guides"><li><a class="dropdown-item" href="../articles/getting-started.html">Getting Started with pairwiseLLM</a></li>
    <li><a class="dropdown-item" href="../articles/advanced-batch-workflows.html">Advanced: Submitting and Polling Multiple Batches</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../articles/prompt-template-bias.html">Template Positional Bias</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/shmercer/pairwiseLLM/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-index">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Package index</h1>
    </div>

    <div class="section level2">
      <h2 id="all-functions">All functions<a class="anchor" aria-label="anchor" href="#all-functions"></a></h2>



      <dl></dl></div><div class="section level2">




      <dl><dt>

          <code><a href="alternate_pair_order.html">alternate_pair_order()</a></code>

        </dt>
        <dd>Deterministically alternate sample order in pairs</dd>

        <dt>

          <code><a href="anthropic_compare_pair_live.html">anthropic_compare_pair_live()</a></code>

        </dt>
        <dd>Live Anthropic (Claude) comparison for a single pair of samples</dd>

        <dt>

          <code><a href="anthropic_create_batch.html">anthropic_create_batch()</a></code>

        </dt>
        <dd>Create an Anthropic Message Batch</dd>

        <dt>

          <code><a href="anthropic_download_batch_results.html">anthropic_download_batch_results()</a></code>

        </dt>
        <dd>Download Anthropic Message Batch results (.jsonl)</dd>

        <dt>

          <code><a href="anthropic_get_batch.html">anthropic_get_batch()</a></code>

        </dt>
        <dd>Retrieve an Anthropic Message Batch by ID</dd>

        <dt>

          <code><a href="anthropic_poll_batch_until_complete.html">anthropic_poll_batch_until_complete()</a></code>

        </dt>
        <dd>Poll an Anthropic Message Batch until completion</dd>

        <dt>

          <code><a href="bt_adaptive_round.html">bt_adaptive_round()</a></code>

        </dt>
        <dd>Run one adaptive round: compute metrics, decide stopping, and propose next pairs</dd>

        <dt>

          <code><a href="bt_core_link_round.html">bt_core_link_round()</a></code>

        </dt>
        <dd>Propose a core-linking round given an existing BT fit</dd>

        <dt>

          <code><a href="bt_run_adaptive.html">bt_run_adaptive()</a></code>

        </dt>
        <dd>Run a round-based adaptive BT workflow end-to-end</dd>

        <dt>

          <code><a href="bt_should_stop.html">bt_should_stop()</a></code>

        </dt>
        <dd>Decide whether to stop adaptive sampling based on stop metrics</dd>

        <dt>

          <code><a href="bt_stop_metrics.html">bt_stop_metrics()</a></code>

        </dt>
        <dd>Compute stopping metrics from a Bradley–Terry model fit</dd>

        <dt>

          <code><a href="build_anthropic_batch_requests.html">build_anthropic_batch_requests()</a></code>

        </dt>
        <dd>Build Anthropic Message Batch requests from a tibble of pairs</dd>

        <dt>

          <code><a href="build_bt_data.html">build_bt_data()</a></code>

        </dt>
        <dd>Build Bradley-Terry comparison data from pairwise results</dd>

        <dt>

          <code><a href="build_elo_data.html">build_elo_data()</a></code>

        </dt>
        <dd>Build EloChoice comparison data from pairwise results</dd>

        <dt>

          <code><a href="build_gemini_batch_requests.html">build_gemini_batch_requests()</a></code>

        </dt>
        <dd>Build Gemini batch requests from a tibble of pairs</dd>

        <dt>

          <code><a href="build_openai_batch_requests.html">build_openai_batch_requests()</a></code>

        </dt>
        <dd>Build OpenAI batch JSONL lines for paired comparisons</dd>

        <dt>

          <code><a href="build_prompt.html">build_prompt()</a></code>

        </dt>
        <dd>Build a concrete LLM prompt from a template</dd>

        <dt>

          <code><a href="check_llm_api_keys.html">check_llm_api_keys()</a></code>

        </dt>
        <dd>Check configured API keys for LLM backends</dd>

        <dt>

          <code><a href="check_positional_bias.html">check_positional_bias()</a></code>

        </dt>
        <dd>Check positional bias and bootstrap consistency reliability</dd>

        <dt>

          <code><a href="compute_reverse_consistency.html">compute_reverse_consistency()</a></code>

        </dt>
        <dd>Compute consistency between forward and reverse pair comparisons</dd>

        <dt>

          <code><a href="ensure_only_ollama_model_loaded.html">ensure_only_ollama_model_loaded()</a></code>

        </dt>
        <dd>Ensure only one Ollama model is loaded in memory</dd>

        <dt>

          <code><a href="estimate_llm_pairs_cost.html">estimate_llm_pairs_cost()</a></code>

        </dt>
        <dd>Estimate LLM token usage and cost for a set of pairwise comparisons</dd>

        <dt>

          <code><a href="example_openai_batch_output.html">example_openai_batch_output</a></code>

        </dt>
        <dd>Example OpenAI Batch output (JSONL lines)</dd>

        <dt>

          <code><a href="example_writing_pairs.html">example_writing_pairs</a></code>

        </dt>
        <dd>Example dataset of paired comparisons for writing samples</dd>

        <dt>

          <code><a href="example_writing_samples.html">example_writing_samples</a></code>

        </dt>
        <dd>Example dataset of writing samples</dd>

        <dt>

          <code><a href="fit_bt_model.html">fit_bt_model()</a></code>

        </dt>
        <dd>Fit a Bradley–Terry model with sirt and fallback to BradleyTerry2</dd>

        <dt>

          <code><a href="fit_elo_model.html">fit_elo_model()</a></code>

        </dt>
        <dd>Fit an EloChoice model to pairwise comparison data</dd>

        <dt>

          <code><a href="gemini_compare_pair_live.html">gemini_compare_pair_live()</a></code>

        </dt>
        <dd>Live Google Gemini comparison for a single pair of samples</dd>

        <dt>

          <code><a href="gemini_create_batch.html">gemini_create_batch()</a></code>

        </dt>
        <dd>Create a Gemini Batch job from request objects</dd>

        <dt>

          <code><a href="gemini_download_batch_results.html">gemini_download_batch_results()</a></code>

        </dt>
        <dd>Download Gemini Batch results to a JSONL file</dd>

        <dt>

          <code><a href="gemini_get_batch.html">gemini_get_batch()</a></code>

        </dt>
        <dd>Retrieve a Gemini Batch job by name</dd>

        <dt>

          <code><a href="gemini_poll_batch_until_complete.html">gemini_poll_batch_until_complete()</a></code>

        </dt>
        <dd>Poll a Gemini Batch job until completion</dd>

        <dt>

          <code><a href="get_prompt_template.html">get_prompt_template()</a></code>

        </dt>
        <dd>Retrieve a named prompt template</dd>

        <dt>

          <code><a href="list_prompt_templates.html">list_prompt_templates()</a></code>

        </dt>
        <dd>List available prompt templates</dd>

        <dt>

          <code><a href="llm_compare_pair.html">llm_compare_pair()</a></code>

        </dt>
        <dd>Backend-agnostic live comparison for a single pair of samples</dd>

        <dt>

          <code><a href="llm_download_batch_results.html">llm_download_batch_results()</a></code>

        </dt>
        <dd>Extract results from a pairwiseLLM batch object</dd>

        <dt>

          <code><a href="llm_resume_multi_batches.html">llm_resume_multi_batches()</a></code>

        </dt>
        <dd>Resume polling and download results for multiple batch jobs</dd>

        <dt>

          <code><a href="llm_submit_pairs_batch.html">llm_submit_pairs_batch()</a></code>

        </dt>
        <dd>Submit pairs to an LLM backend via batch API</dd>

        <dt>

          <code><a href="llm_submit_pairs_multi_batch.html">llm_submit_pairs_multi_batch()</a></code>

        </dt>
        <dd>Multi‑batch submission and polling wrappers</dd>

        <dt>

          <code><a href="make_pairs.html">make_pairs()</a></code>

        </dt>
        <dd>Create all unordered pairs of writing samples</dd>

        <dt>

          <code><a href="ollama_compare_pair_live.html">ollama_compare_pair_live()</a></code>

        </dt>
        <dd>Live Ollama comparison for a single pair of samples</dd>

        <dt>

          <code><a href="openai_compare_pair_live.html">openai_compare_pair_live()</a></code>

        </dt>
        <dd>Live OpenAI comparison for a single pair of samples</dd>

        <dt>

          <code><a href="openai_create_batch.html">openai_create_batch()</a></code>

        </dt>
        <dd>Create an OpenAI batch from an uploaded file</dd>

        <dt>

          <code><a href="openai_download_batch_output.html">openai_download_batch_output()</a></code>

        </dt>
        <dd>Download the output file for a completed batch</dd>

        <dt>

          <code><a href="openai_get_batch.html">openai_get_batch()</a></code>

        </dt>
        <dd>Retrieve an OpenAI batch</dd>

        <dt>

          <code><a href="openai_poll_batch_until_complete.html">openai_poll_batch_until_complete()</a></code>

        </dt>
        <dd>Poll an OpenAI batch until it completes or fails</dd>

        <dt>

          <code><a href="openai_upload_batch_file.html">openai_upload_batch_file()</a></code>

        </dt>
        <dd>Upload a JSONL batch file to OpenAI</dd>

        <dt>

          <code><a href="parse_anthropic_batch_output.html">parse_anthropic_batch_output()</a></code>

        </dt>
        <dd>Parse Anthropic Message Batch output into a tibble</dd>

        <dt>

          <code><a href="parse_gemini_batch_output.html">parse_gemini_batch_output()</a></code>

        </dt>
        <dd>Parse Gemini batch JSONL output into a tibble of pairwise results</dd>

        <dt>

          <code><a href="parse_openai_batch_output.html">parse_openai_batch_output()</a></code>

        </dt>
        <dd>Parse an OpenAI Batch output JSONL file</dd>

        <dt>

          <code><a href="print.pairwiseLLM_cost_estimate.html">print(<i>&lt;pairwiseLLM_cost_estimate&gt;</i>)</a></code>

        </dt>
        <dd>Print a pairwiseLLM cost estimate</dd>

        <dt>

          <code><a href="randomize_pair_order.html">randomize_pair_order()</a></code>

        </dt>
        <dd>Randomly assign samples to positions SAMPLE_1 and SAMPLE_2</dd>

        <dt>

          <code><a href="read_samples_df.html">read_samples_df()</a></code>

        </dt>
        <dd>Read writing samples from a data frame</dd>

        <dt>

          <code><a href="read_samples_dir.html">read_samples_dir()</a></code>

        </dt>
        <dd>Read writing samples from a directory of .txt files</dd>

        <dt>

          <code><a href="register_prompt_template.html">register_prompt_template()</a></code>

        </dt>
        <dd>Register a named prompt template</dd>

        <dt>

          <code><a href="remove_prompt_template.html">remove_prompt_template()</a></code>

        </dt>
        <dd>Remove a registered prompt template</dd>

        <dt>

          <code><a href="run_anthropic_batch_pipeline.html">run_anthropic_batch_pipeline()</a></code>

        </dt>
        <dd>Run an Anthropic batch pipeline for pairwise comparisons</dd>

        <dt>

          <code><a href="run_gemini_batch_pipeline.html">run_gemini_batch_pipeline()</a></code>

        </dt>
        <dd>Run a Gemini batch pipeline for pairwise comparisons</dd>

        <dt>

          <code><a href="run_openai_batch_pipeline.html">run_openai_batch_pipeline()</a></code>

        </dt>
        <dd>Run a full OpenAI batch pipeline for pairwise comparisons</dd>

        <dt>

          <code><a href="sample_pairs.html">sample_pairs()</a></code>

        </dt>
        <dd>Randomly sample pairs of writing samples</dd>

        <dt>

          <code><a href="sample_reverse_pairs.html">sample_reverse_pairs()</a></code>

        </dt>
        <dd>Sample reversed versions of a subset of pairs</dd>

        <dt>

          <code><a href="select_adaptive_pairs.html">select_adaptive_pairs()</a></code>

        </dt>
        <dd>Select adaptive pairs for the next round of comparisons</dd>

        <dt>

          <code><a href="select_core_link_pairs.html">select_core_link_pairs()</a></code>

        </dt>
        <dd>Select core-linking pairs for BT scaling across batches/waves</dd>

        <dt>

          <code><a href="select_core_set.html">select_core_set()</a></code>

        </dt>
        <dd>Select a core set of items for BT linking</dd>

        <dt>

          <code><a href="set_prompt_template.html">set_prompt_template()</a></code>

        </dt>
        <dd>Get or set a prompt template for pairwise comparisons</dd>

        <dt>

          <code><a href="simulate_bt_judge.html">simulate_bt_judge()</a></code>

        </dt>
        <dd>Simulate a judge for BT pairwise comparisons</dd>

        <dt>

          <code><a href="submit_anthropic_pairs_live.html">submit_anthropic_pairs_live()</a></code>

        </dt>
        <dd>Live Anthropic (Claude) comparisons for a tibble of pairs</dd>

        <dt>

          <code><a href="submit_gemini_pairs_live.html">submit_gemini_pairs_live()</a></code>

        </dt>
        <dd>Live Google Gemini comparisons for a tibble of pairs</dd>

        <dt>

          <code><a href="submit_llm_pairs.html">submit_llm_pairs()</a></code>

        </dt>
        <dd>Backend-agnostic live comparisons for a tibble of pairs</dd>

        <dt>

          <code><a href="submit_ollama_pairs_live.html">submit_ollama_pairs_live()</a></code>

        </dt>
        <dd>Live Ollama comparisons for a tibble of pairs</dd>

        <dt>

          <code><a href="submit_openai_pairs_live.html">submit_openai_pairs_live()</a></code>

        </dt>
        <dd>Live OpenAI comparisons for a tibble of pairs</dd>

        <dt>

          <code><a href="submit_together_pairs_live.html">submit_together_pairs_live()</a></code>

        </dt>
        <dd>Live Together.ai comparisons for a tibble of pairs</dd>

        <dt>

          <code><a href="summarize_bt_fit.html">summarize_bt_fit()</a></code>

        </dt>
        <dd>Summarize a Bradley–Terry model fit</dd>

        <dt>

          <code><a href="together_compare_pair_live.html">together_compare_pair_live()</a></code>

        </dt>
        <dd>Live Together.ai comparison for a single pair of samples</dd>

        <dt>

          <code><a href="trait_description.html">trait_description()</a></code>

        </dt>
        <dd>Get a trait name and description for prompts</dd>

        <dt>

          <code><a href="write_openai_batch_file.html">write_openai_batch_file()</a></code>

        </dt>
        <dd>Write an OpenAI batch table to a JSONL file</dd>
      </dl></div>
  </main></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Sterett H. Mercer.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>


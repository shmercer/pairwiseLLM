# Build OpenAI batch JSONL lines for paired comparisons

This helper constructs one JSON object per pair of writing samples,
suitable for use with the OpenAI batch API. It supports both
`/v1/chat/completions` and `/v1/responses` endpoints.

## Usage

``` r
build_openai_batch_requests(
  pairs,
  model,
  trait_name,
  trait_description,
  prompt_template = set_prompt_template(),
  endpoint = c("chat.completions", "responses"),
  temperature = NULL,
  top_p = NULL,
  logprobs = NULL,
  reasoning = NULL,
  include_thoughts = FALSE,
  request_id_prefix = "EXP"
)
```

## Arguments

- pairs:

  A data frame or tibble with columns `ID1`, `text1`, `ID2`, and
  `text2`.

- model:

  Character scalar giving the OpenAI model name (e.g., `"gpt-4.1"`,
  `"gpt-5.1"`).

- trait_name:

  Short label for the trait (e.g., "Overall Quality").

- trait_description:

  Full-text definition of the trait.

- prompt_template:

  Character template containing the placeholders `{TRAIT_NAME}`,
  `{TRAIT_DESCRIPTION}`, `{SAMPLE_1}`, and `{SAMPLE_2}`. Defaults to
  [`set_prompt_template()`](https://shmercer.github.io/pairwiseLLM/reference/set_prompt_template.md).

- endpoint:

  Which OpenAI endpoint to target. One of `"chat.completions"` (default)
  or `"responses"`.

- temperature:

  Optional temperature parameter (see OpenAI docs).

- top_p:

  Optional top_p parameter.

- logprobs:

  Optional logprobs parameter.

- reasoning:

  Optional reasoning effort for `gpt-5.1` when using the `/v1/responses`
  endpoint. Typically `"none"`, `"low"`, `"medium"`, or `"high"`.

- include_thoughts:

  Logical; if TRUE and `endpoint = "responses"`, and `reasoning` is not
  `"none"`, adds `summary = "auto"` to the `reasoning` block so that
  reasoning summaries (thoughts) are returned and can be parsed into a
  `thoughts` column by
  [`parse_openai_batch_output`](https://shmercer.github.io/pairwiseLLM/reference/parse_openai_batch_output.md).
  When `endpoint = "responses"`, `include_thoughts = TRUE`, and the
  model is `"gpt-5.1"` with no explicit `reasoning`, the function
  defaults `reasoning` to `"low"`. Has no effect for
  `"chat.completions"`.

- request_id_prefix:

  String prefix for `custom_id`; the full ID takes the form
  `"<prefix>_<ID1>_vs_<ID2>"`.

## Value

A tibble with one row per pair and columns:

- `custom_id`: ID string used by the batch API.

- `method`: HTTP method (`"POST"`).

- `url`: Endpoint path (`"/v1/chat/completions"` or `"/v1/responses"`).

- `body`: List column containing the request body.

## Details

Each row in `pairs` must contain columns `ID1`, `text1`, `ID2`, and
`text2`. For each pair, a prompt is generated by filling a template (see
[`set_prompt_template`](https://shmercer.github.io/pairwiseLLM/reference/set_prompt_template.md)
and
[`build_prompt`](https://shmercer.github.io/pairwiseLLM/reference/build_prompt.md))
and then wrapped in the appropriate request body structure.

## Examples

``` r
if (FALSE) { # \dontrun{
# Requires OPENAI_API_KEY and network access.
library(pairwiseLLM)

data("example_writing_samples", package = "pairwiseLLM")

pairs <- example_writing_samples |>
  make_pairs() |>
  sample_pairs(n_pairs = 3, seed = 123) |>
  randomize_pair_order(seed = 456)

td <- trait_description("overall_quality")
tmpl <- set_prompt_template()

# Basic chat.completions batch (no thoughts)
batch_tbl_chat <- build_openai_batch_requests(
  pairs             = pairs,
  model             = "gpt-4.1",
  trait_name        = td$name,
  trait_description = td$description,
  prompt_template   = tmpl,
  endpoint          = "chat.completions",
  temperature       = 0
)

# Responses endpoint with reasoning summaries (thoughts) for gpt-5.1
batch_tbl_resp <- build_openai_batch_requests(
  pairs             = pairs,
  model             = "gpt-5.1",
  trait_name        = td$name,
  trait_description = td$description,
  prompt_template   = tmpl,
  endpoint          = "responses",
  include_thoughts  = TRUE # will set reasoning = "low" by default
)

batch_tbl_chat
batch_tbl_resp
} # }
```
